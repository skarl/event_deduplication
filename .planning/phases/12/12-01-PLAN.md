---
phase: 12-export
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/event_dedup/export/__init__.py
  - src/event_dedup/export/service.py
  - src/event_dedup/api/routes/export.py
  - src/event_dedup/api/app.py
  - src/event_dedup/api/schemas.py
  - tests/test_export.py
autonomous: true
requirements: [EXP-01, EXP-02, EXP-03]

must_haves:
  truths:
    - "Canonical events can be exported as JSON matching the input event format (title, event_dates, location with nested geo, categories, flags)"
    - "Export with created_after filter returns only events created at or after that timestamp"
    - "Export with modified_after filter returns only events modified at or after that timestamp"
    - "Export of >200 events splits into multiple 200-event chunk files with correct naming"
    - "Export of <=200 events returns a single JSON file directly"
    - "Export of >200 events returns a ZIP archive containing all chunk files"
    - "Export of zero matching events returns a single JSON with empty events array"
  artifacts:
    - path: "src/event_dedup/export/service.py"
      provides: "Core export logic: query, transform, chunk"
      exports: ["canonical_to_input_format", "query_and_export", "chunk_events"]
    - path: "src/event_dedup/api/routes/export.py"
      provides: "POST /api/export endpoint"
      exports: ["router"]
    - path: "tests/test_export.py"
      provides: "Unit and integration tests for export service and API"
      min_lines: 80
  key_links:
    - from: "src/event_dedup/api/routes/export.py"
      to: "src/event_dedup/export/service.py"
      via: "import and call query_and_export"
      pattern: "from event_dedup\\.export\\.service import"
    - from: "src/event_dedup/api/app.py"
      to: "src/event_dedup/api/routes/export.py"
      via: "router registration"
      pattern: "include_router.*export"
    - from: "src/event_dedup/export/service.py"
      to: "src/event_dedup/models/canonical_event.py"
      via: "SQLAlchemy query and field access"
      pattern: "CanonicalEvent"
---

<objective>
Build the core export service module and API endpoint for exporting canonical events as JSON in the input format.

Purpose: Provide the backend foundation that both the API endpoint and CLI command (Plan 02) will use. The export service handles querying with date filters, transforming CanonicalEvent DB rows to input-format JSON, chunking into 200-event files, and packaging as single JSON or ZIP archive.

Output: Working `POST /api/export` endpoint, shared `export/service.py` module, comprehensive tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12/12-RESEARCH.md
@src/event_dedup/models/canonical_event.py
@src/event_dedup/ingestion/json_loader.py
@src/event_dedup/api/app.py
@src/event_dedup/api/deps.py
@src/event_dedup/api/schemas.py
@tests/conftest.py

<interfaces>
<!-- Key types and contracts the executor needs. Extracted from codebase. -->

From src/event_dedup/models/canonical_event.py (CanonicalEvent fields to export):
```python
class CanonicalEvent(Base):
    __tablename__ = "canonical_events"
    id: Mapped[int]
    title: Mapped[str]
    short_description: Mapped[str | None]
    description: Mapped[str | None]
    highlights: Mapped[list | None]  # JSON
    location_name: Mapped[str | None]
    location_city: Mapped[str | None]
    location_district: Mapped[str | None]
    location_street: Mapped[str | None]
    location_zipcode: Mapped[str | None]
    geo_latitude: Mapped[float | None]
    geo_longitude: Mapped[float | None]
    geo_confidence: Mapped[float | None]
    dates: Mapped[list | None]  # JSON: [{"date": "...", "start_time": "...", ...}]
    categories: Mapped[list | None]  # JSON
    is_family_event: Mapped[bool | None]
    is_child_focused: Mapped[bool | None]
    admission_free: Mapped[bool | None]
    created_at: Mapped[datetime]
    updated_at: Mapped[datetime]
```

From src/event_dedup/ingestion/json_loader.py (target output format):
```python
# Each exported event must match this structure (minus source-only fields):
{
    "title": str,
    "short_description": str | None,
    "description": str | None,
    "highlights": list[str] | None,
    "event_dates": [{"date": str, "start_time": str | None, "end_time": str | None, "end_date": str | None}],
    "location": {
        "name": str | None, "city": str | None, "district": str | None,
        "street": str | None, "zipcode": str | None,
        "geo": {"longitude": float | None, "latitude": float | None, "confidence": float | None}
    },
    "categories": list[str] | None,
    "is_family_event": bool | None,
    "is_child_focused": bool | None,
    "admission_free": bool | None,
}
```

From src/event_dedup/api/deps.py:
```python
async def get_db() -> AsyncGenerator[AsyncSession, None]:
    factory = get_session_factory()
    async with factory() as session:
        yield session
```

From tests/conftest.py (test patterns):
- Uses `create_async_engine("sqlite+aiosqlite:///:memory:")` for test DB
- `api_client` fixture overrides `get_db` dependency
- `seeded_db` fixture creates sample CanonicalEvent rows
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create export service module with tests (RED then GREEN)</name>
  <files>
    src/event_dedup/export/__init__.py
    src/event_dedup/export/service.py
    tests/test_export.py
  </files>
  <action>
**RED phase -- write tests first in `tests/test_export.py`:**

1. **Test `canonical_to_input_format` transformation:**
   - Create a `CanonicalEvent` ORM object with all fields populated (title, short_description, description, highlights, location_*, geo_*, dates as JSON, categories, is_family_event, is_child_focused, admission_free)
   - Assert output dict has `event_dates` (NOT `dates`), nested `location.geo` structure, all optional fields present
   - Test with minimal event (only title + dates) -- assert no empty location/geo keys in output
   - Test with None geo fields -- assert no `geo` key in location

2. **Test `chunk_events` function:**
   - Test with 150 events (1 chunk): returns 1 tuple of (filename, json_string)
   - Test with 450 events (3 chunks): returns 3 tuples, filenames match `export_{timestamp}_part_{1,2,3}.json`
   - Test with 0 events: returns 1 tuple with empty events array
   - Verify each chunk's JSON parses and has `events` array and `metadata` with `eventCount`, `part`, `totalParts`

3. **Test `query_and_export` (integration with DB):**
   - Use `test_session_factory` and `seeded_db` fixtures from conftest
   - Test no filters: returns all events as transformed dicts
   - Test `created_after` filter: seed events with known timestamps, verify filter works
   - Test `modified_after` filter: same approach
   - Test both filters combined (AND semantics)

**GREEN phase -- implement `src/event_dedup/export/service.py`:**

Create `src/event_dedup/export/__init__.py` (empty).

Create `src/event_dedup/export/service.py` with three public functions:

```python
EXPORT_CHUNK_SIZE = 200

def canonical_to_input_format(canonical: CanonicalEvent) -> dict:
    """Transform a CanonicalEvent ORM object to input JSON format."""
```
- Map `dates` -> `event_dates`
- Construct nested `location` dict from flat `location_*` fields
- Nest `geo` inside `location` only when lat/lng are not None
- Only include optional fields when they have values (not None/empty)
- Omit source-level fields (id, source_type, registration_*, confidence_score, _batch_index, _extracted_at)

```python
def chunk_events(events: list[dict], chunk_size: int = EXPORT_CHUNK_SIZE) -> list[tuple[str, str]]:
    """Split events into named JSON chunks. Returns list of (filename, json_content)."""
```
- Use `datetime.now(timezone.utc).strftime("%Y-%m-%dT%H-%M")` for timestamp
- Each chunk is a complete JSON: `{"events": [...], "metadata": {"exportedAt": ..., "eventCount": N, "part": P, "totalParts": T, "filters": ...}}`
- Handle 0 events: return single file with empty array
- Use `json.dumps(ensure_ascii=False, indent=2)`

```python
async def query_and_export(
    session: AsyncSession,
    created_after: datetime | None = None,
    modified_after: datetime | None = None,
) -> list[dict]:
    """Query canonical events with optional date filters, return as input-format dicts."""
```
- Build SQLAlchemy select with optional `where` clauses on `created_at` and `updated_at`
- Order by `CanonicalEvent.id` for deterministic output
- Transform each result through `canonical_to_input_format`
- Parse datetime strings with `datetime.fromisoformat()` -- accept naive datetimes, assume UTC

Run tests to confirm GREEN.
  </action>
  <verify>
    <automated>cd /Users/svenkarl/workspaces/event-deduplication && uv run pytest tests/test_export.py -x -v</automated>
  </verify>
  <done>
    - `canonical_to_input_format` correctly maps all CanonicalEvent fields to input format with nested location.geo
    - `chunk_events` splits into 200-event files with correct naming and metadata
    - `query_and_export` queries DB with date filters and returns transformed events
    - All tests pass
  </done>
</task>

<task type="auto">
  <name>Task 2: Create API endpoint and register router</name>
  <files>
    src/event_dedup/api/routes/export.py
    src/event_dedup/api/app.py
    src/event_dedup/api/schemas.py
    tests/test_export.py
  </files>
  <action>
1. **Add request/response schemas to `src/event_dedup/api/schemas.py`:**

```python
class ExportRequest(BaseModel):
    created_after: str | None = None  # ISO datetime string
    modified_after: str | None = None  # ISO datetime string
```

2. **Create `src/event_dedup/api/routes/export.py`:**

```python
router = APIRouter(prefix="/api/export", tags=["export"])

@router.post("")
async def export_events(
    request: ExportRequest,
    db: AsyncSession = Depends(get_db),
) -> StreamingResponse:
```

Implementation:
- Parse `created_after` / `modified_after` from request body using `datetime.fromisoformat()` (wrap in try/except, return 400 on parse error)
- Call `query_and_export(session, created_after, modified_after)`
- Call `chunk_events(events)` to get list of (filename, content) tuples
- If single chunk: return `StreamingResponse` with `media_type="application/json"` and `Content-Disposition: attachment; filename="..."` header
- If multiple chunks: create in-memory ZIP with `zipfile.ZipFile(BytesIO(), "w", ZIP_DEFLATED)`, write each chunk as a file entry, return `StreamingResponse` with `media_type="application/zip"` and ZIP filename `export_{timestamp}.zip`
- Pass the `filters` info (created_after, modified_after as strings or null) into `chunk_events` so metadata includes the filter values used

3. **Register router in `src/event_dedup/api/app.py`:**
- Add import: `from event_dedup.api.routes.export import router as export_router`
- Add: `app.include_router(export_router)`

4. **Add API integration tests to `tests/test_export.py`:**
- Test `POST /api/export` with empty body (no filters): returns 200 with `application/json`, Content-Disposition has `.json` filename, body parses as valid JSON with `events` array
- Test `POST /api/export` with `created_after` filter: returns filtered results
- Test empty result: returns JSON with empty `events` array (not 404 or 500)
- Test invalid datetime string: returns 400/422

Run all export tests to confirm everything passes.
  </action>
  <verify>
    <automated>cd /Users/svenkarl/workspaces/event-deduplication && uv run pytest tests/test_export.py -x -v</automated>
  </verify>
  <done>
    - `POST /api/export` returns JSON for <=200 events with correct Content-Disposition header
    - `POST /api/export` returns ZIP for >200 events
    - Date filters work correctly through the API
    - Empty exports return valid JSON with empty events array
    - Invalid datetime inputs return appropriate error
    - Router is registered in app.py
    - All tests pass
  </done>
</task>

</tasks>

<verification>
1. `uv run pytest tests/test_export.py -x -v` -- all export tests pass
2. `uv run pytest tests/ -x --timeout=60` -- full test suite still passes (no regressions)
3. Manual verification: `curl -X POST http://localhost:8000/api/export -H 'Content-Type: application/json' -d '{}'` returns JSON with events
</verification>

<success_criteria>
- Export service module exists at `src/event_dedup/export/service.py` with `canonical_to_input_format`, `chunk_events`, and `query_and_export` functions
- API endpoint `POST /api/export` is registered and functional
- Transformation produces correct nested JSON matching input format (event_dates, location.geo)
- Chunking splits at 200 events with correct file naming
- API returns JSON for <=200 events, ZIP for >200 events
- Date filters (created_after, modified_after) correctly filter exported events
- Empty export returns valid JSON with empty events array
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/12/12-01-SUMMARY.md`
</output>
