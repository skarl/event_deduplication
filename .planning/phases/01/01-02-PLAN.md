---
phase: 01-foundation
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - src/event_dedup/preprocessing/__init__.py
  - src/event_dedup/preprocessing/normalizer.py
  - src/event_dedup/preprocessing/prefix_stripper.py
  - src/event_dedup/preprocessing/blocking.py
  - src/event_dedup/config/prefixes.yaml
  - src/event_dedup/config/city_aliases.yaml
  - src/event_dedup/config/settings.py
  - src/event_dedup/ingestion/file_processor.py
  - tests/test_normalizer.py
  - tests/test_prefix_stripper.py
  - tests/test_blocking.py
autonomous: true
requirements:
  - PIPE-02
  - PIPE-04

must_haves:
  truths:
    - "Every ingested event has normalized title, short_description, location_name, and location_city stored in _normalized columns"
    - "German umlauts are expanded (ae/oe/ue/ss) and text is lowercased in all normalized fields"
    - "Known source-specific prefixes are stripped from normalized titles"
    - "Every ingested event with a city has a date+city blocking key"
    - "Events with geo confidence >= 0.85 and coordinates within the Breisgau bounding box also have date+geo_grid blocking keys"
    - "City aliases map districts to parent municipalities (Waltershofen -> Freiburg im Breisgau, Nordweil -> Kenzingen, etc.)"
  artifacts:
    - path: "src/event_dedup/preprocessing/normalizer.py"
      provides: "Text normalization pipeline"
      exports: ["normalize_text", "normalize_city"]
    - path: "src/event_dedup/preprocessing/prefix_stripper.py"
      provides: "Configurable prefix stripping"
      exports: ["strip_prefixes", "PrefixConfig", "load_prefix_config"]
    - path: "src/event_dedup/preprocessing/blocking.py"
      provides: "Blocking key generation"
      exports: ["generate_blocking_keys", "geo_grid_key"]
    - path: "src/event_dedup/config/prefixes.yaml"
      provides: "Initial prefix configuration from research analysis"
      contains: "Nordwiler Narrenfahrplan"
    - path: "src/event_dedup/config/city_aliases.yaml"
      provides: "District-to-municipality mappings"
      contains: "Waltershofen"
  key_links:
    - from: "src/event_dedup/ingestion/file_processor.py"
      to: "src/event_dedup/preprocessing/normalizer.py"
      via: "Normalizes text fields during ingestion"
      pattern: "normalize_text|normalize_city"
    - from: "src/event_dedup/ingestion/file_processor.py"
      to: "src/event_dedup/preprocessing/blocking.py"
      via: "Generates blocking keys during ingestion"
      pattern: "generate_blocking_keys"
    - from: "src/event_dedup/preprocessing/normalizer.py"
      to: "src/event_dedup/preprocessing/prefix_stripper.py"
      via: "Calls prefix stripping as part of title normalization"
      pattern: "strip_prefixes"
---

<objective>
Implement the text preprocessing pipeline (normalization, prefix stripping, blocking key generation) and integrate it into the file ingestion processor so every ingested event has normalized text and blocking keys ready for matching.

Purpose: Preprocessing is the foundation of matching accuracy. Without correct normalization, fuzzy matching will fail on German umlauts, case differences, and source-specific prefixes. Without blocking keys, candidate generation in Plan 01-03 cannot work. This must be right before any matching or evaluation happens.

Output: Every event ingested via file_processor now has populated _normalized columns and blocking_keys array. Prefix stripping and city alias resolution are config-driven and editable without code changes.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01/01-RESEARCH.md
@.planning/1-CONTEXT.md
@.planning/phases/01/01-01-SUMMARY.md

<interfaces>
<!-- Interfaces from Plan 01-01 that this plan builds upon -->

From src/event_dedup/models/source_event.py:
```python
class SourceEvent(Base):
    __tablename__ = "source_events"
    id: Mapped[str]  # pdf-{hash}-{batch}-{index} natural key
    title: Mapped[str]
    short_description: Mapped[str | None]
    location_name: Mapped[str | None]
    location_city: Mapped[str | None]
    location_district: Mapped[str | None]
    # Normalized fields (to be populated by this plan):
    title_normalized: Mapped[str | None]
    short_description_normalized: Mapped[str | None]
    location_name_normalized: Mapped[str | None]
    location_city_normalized: Mapped[str | None]
    # Blocking keys (to be populated by this plan):
    blocking_keys: Mapped[list[str] | None]
    # Geo fields (used for geo blocking):
    geo_latitude: Mapped[float | None]
    geo_longitude: Mapped[float | None]
    geo_confidence: Mapped[float | None]
```

From src/event_dedup/models/event_date.py:
```python
class EventDate(Base):
    __tablename__ = "event_dates"
    event_id: Mapped[str]  # FK to source_events.id
    date: Mapped[date]
    start_time: Mapped[time | None]
    end_time: Mapped[time | None]
    end_date: Mapped[date | None]
```

From src/event_dedup/ingestion/json_loader.py:
```python
class EventFileData(BaseModel):
    events: list[EventData]
    rejected: list = []
    metadata: FileMetadata | None = None

def load_event_file(file_path: Path) -> EventFileData
def compute_file_hash(file_path: Path) -> str
def extract_source_code(filename: str) -> str
```

From src/event_dedup/ingestion/file_processor.py:
```python
class FileProcessor:
    async def process_file(self, file_path: Path) -> FileProcessResult
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Normalization pipeline, prefix stripping, and blocking key generation</name>
  <files>
    src/event_dedup/preprocessing/__init__.py
    src/event_dedup/preprocessing/normalizer.py
    src/event_dedup/preprocessing/prefix_stripper.py
    src/event_dedup/preprocessing/blocking.py
    src/event_dedup/config/prefixes.yaml
    src/event_dedup/config/city_aliases.yaml
    src/event_dedup/config/settings.py
    tests/test_normalizer.py
    tests/test_prefix_stripper.py
    tests/test_blocking.py
  </files>
  <action>
    **1. Create `src/event_dedup/preprocessing/normalizer.py`:**

    - `normalize_text(text: str) -> str`:
      1. Return empty string for None/empty input
      2. Lowercase the text
      3. Expand German umlauts: ae for a-umlaut, oe for o-umlaut, ue for u-umlaut, ss for eszett. Handle BOTH composed forms (single codepoint: \u00e4, \u00f6, \u00fc, \u00df) AND decomposed forms (base + combining diaeresis: a\u0308, o\u0308, u\u0308). Also handle uppercase variants (\u00c4, \u00d6, \u00dc).
      4. Normalize whitespace (collapse multiple spaces/tabs/newlines to single space, strip)
      5. Strip punctuation: remove `"'!?,.:;()[]{}` but KEEP hyphens (important for German compound words like "SPD-Veranstaltung")
      6. Final strip

    - `normalize_city(city: str, aliases: dict[str, str] | None = None) -> str`:
      1. Return empty string for None/empty
      2. Apply `normalize_text(city)`
      3. If aliases dict provided and normalized city is a key, return the alias value (already normalized)
      4. Return the normalized city

    - `load_city_aliases(config_path: Path) -> dict[str, str]`:
      Load city_aliases.yaml, normalize all keys and values, return as dict.

    **2. Create `src/event_dedup/config/city_aliases.yaml`:**

    Initial content based on research findings (Section on district-to-municipality mappings):
    ```yaml
    # City alias mappings: district/neighborhood -> parent municipality
    # Used during normalization to ensure consistent city-based blocking
    # Keys and values should be written in original German (normalization applied at load time)

    # Kenzingen districts
    Nordweil: Kenzingen
    Hecklingen: Kenzingen
    Bombach: Kenzingen

    # Emmendingen districts
    Mundingen: Emmendingen
    Kollmarsreute: Emmendingen
    Wasser: Emmendingen
    Windenreute: Emmendingen
    Maleck: Emmendingen

    # Waldkirch districts
    Kollnau: Waldkirch
    Buchholz: Waldkirch
    Suggental: Waldkirch

    # Freiburg im Breisgau districts
    Waltershofen: Freiburg im Breisgau
    Opfingen: Freiburg im Breisgau
    Tiengen: Freiburg im Breisgau
    Munzingen: Freiburg im Breisgau
    Lehen: Freiburg im Breisgau

    # Gutach im Breisgau
    Bleibach: Gutach im Breisgau

    # Rheinhausen
    Oberhausen: Rheinhausen
    Niederhausen: Rheinhausen
    ```

    **3. Create `src/event_dedup/preprocessing/prefix_stripper.py`:**

    - `class PrefixConfig(BaseModel)`: Pydantic model with fields `dash_prefixes: list[str]`, `colon_prefixes: list[str]`, `generic_prefixes: list[str]`

    - `load_prefix_config(config_path: Path) -> PrefixConfig`: Load prefixes.yaml, return PrefixConfig.

    - `strip_prefixes(title: str, config: PrefixConfig) -> str`:
      1. For each prefix in `config.dash_prefixes`: check if title starts with `"{prefix} - "` or `"{prefix} -- "` or `"{prefix} \u2013 "` (en-dash) or `"{prefix} \u2014 "` (em-dash). Case-insensitive. If match, return everything after the separator, stripped.
      2. For each prefix in `config.colon_prefixes`: check if title starts with `"{prefix}: "`. Case-insensitive. If match, return everything after the colon+space, stripped.
      3. For each prefix in `config.generic_prefixes`: same as dash_prefixes logic.
      4. Return original title if no prefix matched.
      5. IMPORTANT: Only strip the FIRST matching prefix (no recursive stripping).

    **4. Create `src/event_dedup/config/prefixes.yaml`:**

    Use the exact configuration from the research findings:
    ```yaml
    # Configurable prefix patterns for title normalization
    # Stripped during normalization for matching; originals preserved for display

    # Source-specific article prefixes (dash-separated)
    dash_prefixes:
      - "Nordwiler Narrenfahrplan"
      - "Wahlkampfstand Buendnis 90/Die Gruenen"
      - "Kommunales Kino"
      - "Kolping Kids"
      - "Fasnet im Ladhof"
      - "Narrenzunft Bergteufel"

    # Content-type prefixes (colon-separated)
    colon_prefixes:
      - "Vortrag"
      - "Bildervortrag"
      - "Kochworkshop"
      - "FreiTagZeit"
      - "Jungentreff"
      - "Textil-Tag"
      - "SPD-Veranstaltung"
      - "Theaterabend"
      - "Kinderprogramm"
      - "SkF Waldkirch"
      - "Waldkircher Klimagespraech"

    # Generic event-type prefixes (dash-separated, strip only the prefix part)
    generic_prefixes:
      - "Tag der offenen Tuer"
    ```

    IMPORTANT: `prefixes.yaml` should contain original German forms (with real umlauts like Ã¼, not expanded). The normalization pipeline order is:
    1. Strip prefixes from the ORIGINAL title (case-insensitive match against original-form prefixes in the YAML)
    2. Then normalize the result (lowercase, umlaut expansion, punctuation stripping)

    Create a top-level function:
    - `normalize_title(title: str, prefix_config: PrefixConfig) -> str`:
      1. `stripped = strip_prefixes(title, prefix_config)`
      2. `return normalize_text(stripped)`

    **5. Create `src/event_dedup/preprocessing/blocking.py`:**

    - Constants: `GEO_CONFIDENCE_THRESHOLD = 0.85`, `GEO_GRID_LAT = 0.09`, `GEO_GRID_LON = 0.13`, `BOUNDING_BOX = {"lat_min": 47.5, "lat_max": 48.5, "lon_min": 7.3, "lon_max": 8.5}`

    - `geo_grid_key(lat: float, lon: float) -> str`:
      ```python
      cell_lat = round(lat / GEO_GRID_LAT) * GEO_GRID_LAT
      cell_lon = round(lon / GEO_GRID_LON) * GEO_GRID_LON
      return f"{cell_lat:.2f}|{cell_lon:.2f}"
      ```

    - `is_valid_geo(lat: float, lon: float, confidence: float) -> bool`:
      Returns True if confidence >= 0.85 AND coordinates are within the Breisgau bounding box (lat 47.5-48.5, lon 7.3-8.5). This filters out the Ettenheim/Darmstadt outliers.

    - `generate_blocking_keys(dates: list[date], city_normalized: str | None, lat: float | None, lon: float | None, geo_confidence: float | None) -> list[str]`:
      For each date:
      1. If city_normalized is not empty: add `"dc|{date_iso}|{city_normalized}"`
      2. If lat/lon/confidence are all present AND `is_valid_geo(lat, lon, confidence)`: add `"dg|{date_iso}|{geo_grid_key(lat, lon)}"`
      Return deduplicated list of keys.

    **6. Update `src/event_dedup/config/settings.py`:**
    - Add fields: `prefixes_config_path: Path` (default: path to `src/event_dedup/config/prefixes.yaml`), `city_aliases_path: Path` (default: path to `src/event_dedup/config/city_aliases.yaml`)

    **7. Create `tests/test_normalizer.py`:**
    - `test_normalize_lowercase`: "CHECKER TOBI" -> "checker tobi"
    - `test_normalize_umlauts_composed`: "Buergerhaeuser" with actual umlauts -> "buergerhaeuser" (ae/oe/ue)
    - `test_normalize_umlauts_eszett`: text with eszett -> "ss"
    - `test_normalize_whitespace`: "  too   many  spaces  " -> "too many spaces"
    - `test_normalize_punctuation`: "Hart aber herzlich!" -> "hart aber herzlich"
    - `test_normalize_keep_hyphens`: "SPD-Veranstaltung" -> "spd-veranstaltung"
    - `test_normalize_empty`: None and "" both return ""
    - `test_normalize_city_with_alias`: "Waltershofen" with aliases -> "freiburg im breisgau"
    - `test_normalize_city_without_alias`: "Emmendingen" without matching alias -> "emmendingen"
    - `test_normalize_city_case_insensitive`: "WALDKIRCH" -> "waldkirch"

    **8. Create `tests/test_prefix_stripper.py`:**
    - Load the actual prefixes.yaml for testing
    - `test_strip_dash_prefix`: "Nordwiler Narrenfahrplan - Fasnetumzug" -> "Fasnetumzug"
    - `test_strip_colon_prefix`: "Vortrag: Landschaftsmalerei im Fokus" -> "Landschaftsmalerei im Fokus"
    - `test_strip_generic_prefix`: "Tag der offenen Tuer - Kindergarten St. Franziskus" -> "Kindergarten St. Franziskus"
    - `test_no_prefix_match`: "Primel-Aktion Emmendingen" -> unchanged
    - `test_case_insensitive`: "nordwiler narrenfahrplan - Test" -> "Test"
    - `test_en_dash_separator`: "Kommunales Kino \u2013 Der Salzpfad" -> "Der Salzpfad"
    - `test_no_recursive_strip`: Only first matching prefix is stripped

    **9. Create `tests/test_blocking.py`:**
    - `test_date_city_blocking_key`: date 2026-02-12, city "kenzingen" -> ["dc|2026-02-12|kenzingen"]
    - `test_date_geo_blocking_key`: date 2026-02-12, lat 48.19, lon 7.81, confidence 1.0 -> includes a "dg|..." key
    - `test_both_blocking_keys`: event with city AND valid geo gets both dc| and dg| keys
    - `test_low_confidence_no_geo_key`: confidence 0.80 -> no dg| key generated
    - `test_outlier_coordinates_filtered`: lat 49.74 (Darmstadt), confidence 0.848 -> no dg| key (outside bounding box)
    - `test_multi_date_multiple_keys`: 2 dates generate keys for each date
    - `test_no_city_no_geo`: city=None, no geo -> empty list
    - `test_geo_grid_key_consistency`: same coordinates always produce same grid key
    - `test_is_valid_geo_within_bounds`: coordinates within Breisgau -> True
    - `test_is_valid_geo_outside_bounds`: coordinates outside (Darmstadt) -> False even with high confidence
  </action>
  <verify>
    <automated>cd /Users/svenkarl/workspaces/event-deduplication && uv run pytest tests/test_normalizer.py tests/test_prefix_stripper.py tests/test_blocking.py -x -v</automated>
  </verify>
  <done>
    - normalize_text() correctly lowercases, expands umlauts, strips punctuation, keeps hyphens
    - normalize_city() applies aliases for known districts
    - strip_prefixes() removes all configured dash and colon prefixes case-insensitively
    - generate_blocking_keys() produces dc| keys for city-based and dg| keys for geo-based blocking
    - Geo filtering excludes coordinates outside the Breisgau bounding box regardless of confidence
    - prefixes.yaml contains all prefixes from research
    - city_aliases.yaml contains district-to-municipality mappings
    - All preprocessing tests pass
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate preprocessing into file processor</name>
  <files>
    src/event_dedup/ingestion/file_processor.py
    tests/test_file_processor.py
  </files>
  <action>
    **1. Update `src/event_dedup/ingestion/file_processor.py`:**

    - Add preprocessing imports: `from event_dedup.preprocessing.normalizer import normalize_text, normalize_city, load_city_aliases`
    - Add: `from event_dedup.preprocessing.prefix_stripper import load_prefix_config, strip_prefixes`
    - Add: `from event_dedup.preprocessing.blocking import generate_blocking_keys`

    - Update `FileProcessor.__init__` to accept optional `prefix_config_path` and `city_aliases_path` parameters. Load configs at init time (not per-file).

    - Update the event creation loop in `process_file()`:
      After creating the SourceEvent with original fields, also populate:
      ```python
      # Normalize text fields
      stripped_title = strip_prefixes(event.title, self.prefix_config)
      source_event.title_normalized = normalize_text(stripped_title)
      source_event.short_description_normalized = normalize_text(event.short_description) if event.short_description else None
      source_event.location_name_normalized = normalize_text(location_name) if location_name else None
      source_event.location_city_normalized = normalize_city(city, self.city_aliases) if city else None

      # Generate blocking keys from event dates and location
      dates_as_date = [parse_date(d.date) for d in event.event_dates]
      source_event.blocking_keys = generate_blocking_keys(
          dates=dates_as_date,
          city_normalized=source_event.location_city_normalized,
          lat=geo_lat,
          lon=geo_lon,
          geo_confidence=geo_confidence,
      )
      ```

    **2. Update `tests/test_file_processor.py`:**

    - Add `test_process_populates_normalized_fields`: Process bwb file, query first event, verify title_normalized is not None and contains no uppercase, verify umlauts are expanded
    - Add `test_process_strips_prefixes`: Process bwb file, find event "Nordwiler Narrenfahrplan - Kita-Gizig-Umzug", verify title_normalized does NOT contain "nordwiler narrenfahrplan" (prefix was stripped), verify it contains "kita-gizig-umzug" or similar
    - Add `test_process_populates_blocking_keys`: Process bwb file, verify events with a city have at least one blocking key starting with "dc|"
    - Add `test_process_geo_blocking_keys`: Find an event with geo confidence >= 0.85 within Breisgau bounds, verify it has a blocking key starting with "dg|"
    - Add `test_process_city_alias_resolution`: If bwb file has a Nordweil event, verify location_city_normalized is "kenzingen" (mapped from Nordweil via _sanitizeResult.city, which already says Kenzingen -- so this tests the normalization, not alias)

    Ensure all existing tests still pass after the update.
  </action>
  <verify>
    <automated>cd /Users/svenkarl/workspaces/event-deduplication && uv run pytest tests/ -x -v</automated>
  </verify>
  <done>
    - FileProcessor now populates title_normalized, short_description_normalized, location_name_normalized, location_city_normalized for every event
    - FileProcessor generates blocking_keys array for every event
    - Prefix stripping is applied to titles before normalization
    - City aliases are applied during city normalization
    - All existing ingestion tests still pass
    - New preprocessing integration tests pass
    - Full test suite passes with `uv run pytest tests/ -x -v`
  </done>
</task>

</tasks>

<verification>
After both tasks complete:

1. `uv run pytest tests/ -x -v` -- all tests pass (normalizer, prefix_stripper, blocking, json_loader, file_processor)
2. Verify config files exist and are valid: `uv run python -c "from event_dedup.preprocessing.prefix_stripper import load_prefix_config; from pathlib import Path; c = load_prefix_config(Path('src/event_dedup/config/prefixes.yaml')); print(f'Dash: {len(c.dash_prefixes)}, Colon: {len(c.colon_prefixes)}, Generic: {len(c.generic_prefixes)}')"` -- should show counts > 0
3. Verify normalization works end-to-end: `uv run python -c "from event_dedup.preprocessing.normalizer import normalize_text; assert normalize_text('Buergerhaeuser Aeoe') == 'buergerhaeuser aeoe' or True; print(normalize_text('Nordwiler Narrenfahrplan'))"` -- prints lowercase with expanded umlauts
</verification>

<success_criteria>
- Text normalization handles German umlauts (both composed and decomposed), lowercasing, whitespace, and punctuation
- Prefix stripping removes all research-identified prefixes from titles
- City alias resolution maps districts to parent municipalities
- Blocking key generation produces date+city and date+geo_grid keys
- Geo filtering correctly excludes outlier coordinates outside Breisgau bounding box
- All preprocessing is integrated into file_processor -- every ingested event has normalized fields and blocking keys
- Config files (prefixes.yaml, city_aliases.yaml) are editable without code changes
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/01/01-02-SUMMARY.md`
</output>
