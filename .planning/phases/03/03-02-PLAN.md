---
phase: 03-pipeline-integration
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - docker/Dockerfile.worker
  - docker/Dockerfile.api
  - docker/entrypoint.sh
  - docker/nginx-placeholder.html
  - docker-compose.yml
  - .dockerignore
  - src/event_dedup/api/__init__.py
  - src/event_dedup/api/app.py
autonomous: true
requirements:
  - DEPL-01
  - DEPL-02
  - DEPL-03

must_haves:
  truths:
    - "docker-compose up starts PostgreSQL, pipeline worker, API server, and frontend containers"
    - "Pipeline worker container watches the mounted eventdata directory and processes new JSON files"
    - "API server container runs a FastAPI app with a /health endpoint"
    - "Frontend container serves a placeholder page via nginx"
    - "Alembic migrations run automatically on worker container startup before the worker starts"
    - "All configuration is provided via environment variables in docker-compose.yml"
    - "PostgreSQL uses a health check and worker depends_on service_healthy"
  artifacts:
    - path: "docker/Dockerfile.worker"
      provides: "Multi-stage Docker build for pipeline worker using uv"
    - path: "docker/Dockerfile.api"
      provides: "Multi-stage Docker build for FastAPI API server"
    - path: "docker/entrypoint.sh"
      provides: "Entrypoint script that runs Alembic migrations then starts the app"
    - path: "docker-compose.yml"
      provides: "Full stack orchestration: db, worker, api, frontend"
    - path: "src/event_dedup/api/app.py"
      provides: "FastAPI skeleton with /health endpoint"
      exports: ["app"]
    - path: ".dockerignore"
      provides: "Docker build context exclusions"
  key_links:
    - from: "docker-compose.yml"
      to: "docker/Dockerfile.worker"
      via: "worker service build context"
      pattern: "Dockerfile.worker"
    - from: "docker/entrypoint.sh"
      to: "config/alembic.ini"
      via: "Alembic migration command references alembic.ini path"
      pattern: "alembic.*upgrade head"
    - from: "docker-compose.yml"
      to: "src/event_dedup/config/settings.py"
      via: "Environment variables map to Settings fields via EVENT_DEDUP_ prefix"
      pattern: "EVENT_DEDUP_"
---

<objective>
Build the Docker infrastructure that packages the pipeline worker, API server skeleton, and frontend placeholder as separate containers, orchestrated by docker-compose with PostgreSQL. This makes the entire system runnable with a single `docker-compose up` command.

Purpose: Without Docker containers, the system only runs in a development environment. This plan creates deployment-ready infrastructure where dropping a JSON file into a mounted directory triggers end-to-end processing.

Output: Dockerfiles, docker-compose.yml, entrypoint script, FastAPI skeleton, nginx placeholder, .dockerignore.
</objective>

<execution_context>
@.planning/phases/03/03-RESEARCH.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/phases/03/03-CONTEXT.md
@.planning/phases/03/03-RESEARCH.md

<interfaces>
<!-- From Plan 03-01 (must be completed first) -->

Worker entry point:
```
python -m event_dedup.worker
```
Reads settings from environment variables with EVENT_DEDUP_ prefix:
- EVENT_DEDUP_DATABASE_URL: async PostgreSQL URL
- EVENT_DEDUP_DATABASE_URL_SYNC: sync PostgreSQL URL (for Alembic)
- EVENT_DEDUP_EVENT_DATA_DIR: directory to watch for JSON files
- EVENT_DEDUP_DEAD_LETTER_DIR: directory for failed files
- EVENT_DEDUP_MATCHING_CONFIG_PATH: path to matching.yaml
- EVENT_DEDUP_LOG_JSON: "true" for JSON logs
- EVENT_DEDUP_LOG_LEVEL: "INFO", "DEBUG", etc.

Alembic config:
- config/alembic.ini: references script_location = config/alembic
- config/alembic/env.py: supports ALEMBIC_DATABASE_URL env override
- Command: `alembic -c config/alembic.ini upgrade head`

Project structure:
- src/event_dedup/ -- Python package (hatchling src layout)
- config/ -- matching.yaml, alembic.ini, alembic/
- pyproject.toml, uv.lock -- package definition + lockfile
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: FastAPI Skeleton with Health Endpoint</name>
  <files>
    src/event_dedup/api/__init__.py
    src/event_dedup/api/app.py
  </files>
  <action>
1. **Create `src/event_dedup/api/__init__.py`**: Empty file.

2. **Create `src/event_dedup/api/app.py`**:
   - A minimal FastAPI app that Phase 4 will expand with real routes
   - Import `FastAPI` from fastapi
   - Create `app = FastAPI(title="Event Deduplication API", version="0.1.0")`
   - Single route `@app.get("/health")`:
     - Returns `{"status": "ok"}`
   - This is intentionally minimal -- Phase 4 adds all the real endpoints

3. **Update `pyproject.toml`** -- add `"fastapi>=0.115"` and `"uvicorn[standard]>=0.34"` to dependencies (needed for the API container).
   Run `uv sync` after.
  </action>
  <verify>
    <automated>cd /Users/svenkarl/workspaces/event-deduplication && uv sync && uv run python -c "
from event_dedup.api.app import app
from fastapi.testclient import TestClient
client = TestClient(app)
resp = client.get('/health')
assert resp.status_code == 200
assert resp.json() == {'status': 'ok'}
print('FastAPI health endpoint OK')
"</automated>
  </verify>
  <done>
    - FastAPI app with /health endpoint works
    - fastapi and uvicorn dependencies installed
    - Ready for Phase 4 to add real routes
  </done>
</task>

<task type="auto">
  <name>Task 2: Docker Files and Compose</name>
  <files>
    docker/Dockerfile.worker
    docker/Dockerfile.api
    docker/entrypoint.sh
    docker/nginx-placeholder.html
    docker-compose.yml
    .dockerignore
  </files>
  <action>
1. **Create `.dockerignore`**:
   ```
   .git
   .venv
   __pycache__
   *.pyc
   .planning
   .claude
   tests
   *.egg-info
   .ruff_cache
   .pytest_cache
   dead_letters
   eventdata
   ground_truth.db
   ```

2. **Create `docker/entrypoint.sh`**:
   ```bash
   #!/bin/bash
   set -e

   echo "Running database migrations..."
   alembic -c config/alembic.ini upgrade head
   echo "Migrations complete."

   echo "Starting application..."
   exec "$@"
   ```
   - The `exec "$@"` pattern lets docker-compose pass the CMD as arguments
   - Alembic uses ALEMBIC_DATABASE_URL env var (already supported in env.py)

3. **Create `docker/Dockerfile.worker`**:
   - Multi-stage build following the uv Docker guide:
   ```dockerfile
   # Stage 1: Build with uv
   FROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS builder

   ENV UV_COMPILE_BYTECODE=1 \
       UV_LINK_MODE=copy \
       UV_NO_DEV=1 \
       UV_PYTHON_DOWNLOADS=0

   WORKDIR /app

   # Install dependencies (cached unless lock/pyproject changes)
   RUN --mount=type=cache,target=/root/.cache/uv \
       --mount=type=bind,source=uv.lock,target=uv.lock \
       --mount=type=bind,source=pyproject.toml,target=pyproject.toml \
       uv sync --locked --no-install-project --no-editable

   # Copy source and install project
   COPY . /app
   RUN --mount=type=cache,target=/root/.cache/uv \
       uv sync --locked --no-editable

   # Stage 2: Runtime
   FROM python:3.12-slim-bookworm

   # Install pg client for Alembic psycopg2 (needed at runtime for migrations)
   RUN apt-get update && apt-get install -y --no-install-recommends libpq5 && rm -rf /var/lib/apt/lists/*

   RUN groupadd --system --gid 999 app \
       && useradd --system --gid 999 --uid 999 --create-home app

   COPY --from=builder --chown=app:app /app /app

   ENV PATH="/app/.venv/bin:$PATH"
   WORKDIR /app

   COPY docker/entrypoint.sh /entrypoint.sh
   RUN chmod +x /entrypoint.sh

   # Health check: verify worker process is running (pgrep not available in slim images)
   HEALTHCHECK --interval=30s --timeout=5s --retries=3 \
       CMD python -c "import subprocess; subprocess.run(['ps', 'ax'], check=True, capture_output=True)" || exit 1

   USER app
   ENTRYPOINT ["/entrypoint.sh"]
   CMD ["python", "-m", "event_dedup.worker"]
   ```

4. **Create `docker/Dockerfile.api`**:
   - Same multi-stage pattern but with uvicorn CMD:
   ```dockerfile
   FROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS builder

   ENV UV_COMPILE_BYTECODE=1 \
       UV_LINK_MODE=copy \
       UV_NO_DEV=1 \
       UV_PYTHON_DOWNLOADS=0

   WORKDIR /app

   RUN --mount=type=cache,target=/root/.cache/uv \
       --mount=type=bind,source=uv.lock,target=uv.lock \
       --mount=type=bind,source=pyproject.toml,target=pyproject.toml \
       uv sync --locked --no-install-project --no-editable

   COPY . /app
   RUN --mount=type=cache,target=/root/.cache/uv \
       uv sync --locked --no-editable

   FROM python:3.12-slim-bookworm

   RUN apt-get update && apt-get install -y --no-install-recommends libpq5 && rm -rf /var/lib/apt/lists/*

   RUN groupadd --system --gid 999 app \
       && useradd --system --gid 999 --uid 999 --create-home app

   COPY --from=builder --chown=app:app /app /app

   ENV PATH="/app/.venv/bin:$PATH"
   WORKDIR /app

   COPY docker/entrypoint.sh /entrypoint.sh
   RUN chmod +x /entrypoint.sh

   HEALTHCHECK --interval=30s --timeout=5s --retries=3 \
       CMD curl -f http://localhost:8000/health || exit 1

   USER app
   ENTRYPOINT ["/entrypoint.sh"]
   CMD ["uvicorn", "event_dedup.api.app:app", "--host", "0.0.0.0", "--port", "8000"]
   ```

   Note: Install `curl` in runtime stage for health check OR use python-based health check instead:
   ```
   HEALTHCHECK --interval=30s --timeout=5s --retries=3 \
       CMD python -c "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')" || exit 1
   ```
   Use the python-based approach to avoid installing curl.

5. **Create `docker/nginx-placeholder.html`**:
   ```html
   <!DOCTYPE html>
   <html>
   <head><title>Event Deduplication</title></head>
   <body>
   <h1>Event Deduplication Service</h1>
   <p>Frontend will be available in Phase 4.</p>
   <p><a href="http://localhost:8000/docs">API Documentation</a></p>
   </body>
   </html>
   ```

6. **Create `docker-compose.yml`**:
   ```yaml
   services:
     db:
       image: postgres:16-alpine
       environment:
         POSTGRES_DB: event_dedup
         POSTGRES_USER: postgres
         POSTGRES_PASSWORD: postgres
       volumes:
         - pgdata:/var/lib/postgresql/data
       ports:
         - "5432:5432"
       healthcheck:
         test: ["CMD-SHELL", "pg_isready -U postgres -d event_dedup"]
         interval: 5s
         timeout: 5s
         retries: 5

     worker:
       build:
         context: .
         dockerfile: docker/Dockerfile.worker
       environment:
         EVENT_DEDUP_DATABASE_URL: "postgresql+asyncpg://postgres:postgres@db:5432/event_dedup"
         EVENT_DEDUP_DATABASE_URL_SYNC: "postgresql+psycopg2://postgres:postgres@db:5432/event_dedup"
         EVENT_DEDUP_EVENT_DATA_DIR: "/data/events"
         EVENT_DEDUP_DEAD_LETTER_DIR: "/data/dead_letters"
         EVENT_DEDUP_MATCHING_CONFIG_PATH: "config/matching.yaml"
         EVENT_DEDUP_LOG_JSON: "true"
         EVENT_DEDUP_LOG_LEVEL: "INFO"
         ALEMBIC_DATABASE_URL: "postgresql+psycopg2://postgres:postgres@db:5432/event_dedup"
       volumes:
         - ./eventdata:/data/events
         - ./dead_letters:/data/dead_letters
       depends_on:
         db:
           condition: service_healthy

     api:
       build:
         context: .
         dockerfile: docker/Dockerfile.api
       environment:
         EVENT_DEDUP_DATABASE_URL: "postgresql+asyncpg://postgres:postgres@db:5432/event_dedup"
         EVENT_DEDUP_DATABASE_URL_SYNC: "postgresql+psycopg2://postgres:postgres@db:5432/event_dedup"
         ALEMBIC_DATABASE_URL: "postgresql+psycopg2://postgres:postgres@db:5432/event_dedup"
       ports:
         - "8000:8000"
       depends_on:
         db:
           condition: service_healthy

     frontend:
       image: nginx:alpine
       ports:
         - "3000:80"
       volumes:
         - ./docker/nginx-placeholder.html:/usr/share/nginx/html/index.html:ro

   volumes:
     pgdata:
   ```
  </action>
  <verify>
    <automated>cd /Users/svenkarl/workspaces/event-deduplication && docker compose config --quiet && echo "docker-compose.yml is valid"</automated>
  </verify>
  <done>
    - Dockerfile.worker builds multi-stage with uv and runs the pipeline worker
    - Dockerfile.api builds multi-stage with uv and runs FastAPI with uvicorn
    - entrypoint.sh runs Alembic migrations before starting the app
    - docker-compose.yml defines all 4 services with health checks and env vars
    - Frontend serves placeholder page via nginx
    - .dockerignore excludes development/test files from build context
  </done>
</task>

</tasks>

<verification>
```bash
# docker-compose.yml is valid YAML and parses correctly
cd /Users/svenkarl/workspaces/event-deduplication && docker compose config --quiet

# FastAPI health endpoint works
cd /Users/svenkarl/workspaces/event-deduplication && uv run python -c "
from event_dedup.api.app import app
from fastapi.testclient import TestClient
client = TestClient(app)
resp = client.get('/health')
assert resp.status_code == 200
print('Health endpoint OK')
"

# Entrypoint script is executable and valid bash
cd /Users/svenkarl/workspaces/event-deduplication && bash -n docker/entrypoint.sh && echo "entrypoint.sh syntax OK"

# All required files exist
cd /Users/svenkarl/workspaces/event-deduplication && ls -la docker/Dockerfile.worker docker/Dockerfile.api docker/entrypoint.sh docker/nginx-placeholder.html docker-compose.yml .dockerignore

# ALL prior tests still pass (docker changes don't break anything)
cd /Users/svenkarl/workspaces/event-deduplication && uv run pytest tests/ -x -v --timeout=60

# Full stack test (only if Docker is available):
# cd /Users/svenkarl/workspaces/event-deduplication && docker compose build && docker compose up -d && sleep 10 && curl -f http://localhost:8000/health && curl -f http://localhost:3000 && docker compose down
```
</verification>

<success_criteria>
1. `docker-compose up` starts 4 containers: db, worker, api, frontend
2. Worker container runs Alembic migrations on startup via entrypoint.sh
3. Worker container watches /data/events for new JSON files
4. API container responds to GET /health with {"status": "ok"}
5. Frontend container serves the placeholder HTML page on port 3000
6. PostgreSQL uses health check with pg_isready, other services depend on it
7. All configuration via environment variables (EVENT_DEDUP_ prefix + ALEMBIC_DATABASE_URL)
8. .dockerignore excludes dev files from build context
9. Multi-stage Dockerfiles use uv for fast dependency installation
10. ALL prior tests still pass
</success_criteria>

<output>
After completion, create `.planning/phases/03/03-02-SUMMARY.md`
</output>
