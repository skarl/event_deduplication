---
phase: 07-accuracy-refinement
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/event_dedup/matching/config.py
  - src/event_dedup/matching/pipeline.py
  - src/event_dedup/evaluation/harness.py
  - config/matching.yaml
  - tests/test_matching_config.py
  - tests/test_combiner.py
  - tests/test_pipeline.py
  - tests/test_harness.py
autonomous: true
requirements: [MTCH-08]

must_haves:
  truths:
    - "Event pairs sharing a category use category-specific scoring weights instead of defaults"
    - "Category weight overrides are configured in matching.yaml with a priority order"
    - "The combiner function itself is unchanged -- weight resolution happens in the pipeline before calling combined_score"
    - "Evaluation harness can report F1 metrics for specific category subsets of ground truth"
    - "Overall F1 does not regress when category weights are enabled"
  artifacts:
    - path: "src/event_dedup/matching/config.py"
      provides: "CategoryWeightsConfig with per-category ScoringWeights overrides and priority list"
      contains: "category_weights"
    - path: "src/event_dedup/matching/pipeline.py"
      provides: "resolve_weights function and its integration in score_candidate_pairs"
      exports: ["resolve_weights"]
    - path: "src/event_dedup/evaluation/harness.py"
      provides: "Category-specific F1 evaluation function"
      exports: ["evaluate_category_subset"]
    - path: "config/matching.yaml"
      provides: "Category weight overrides for fasnacht and versammlung"
      contains: "category_weights"
  key_links:
    - from: "src/event_dedup/matching/pipeline.py"
      to: "src/event_dedup/matching/config.py"
      via: "resolve_weights reads category_weights from MatchingConfig"
      pattern: "resolve_weights"
    - from: "src/event_dedup/matching/pipeline.py"
      to: "src/event_dedup/matching/combiner.py"
      via: "score_candidate_pairs passes resolved weights to combined_score"
      pattern: "combined_score.*resolve"
    - from: "src/event_dedup/evaluation/harness.py"
      to: "src/event_dedup/evaluation/metrics.py"
      via: "evaluate_category_subset filters pairs then calls compute_metrics"
      pattern: "compute_metrics"
---

<objective>
Implement category-aware matching weights (MTCH-08) and category-specific evaluation.

Purpose: Different event categories have different matching characteristics. Carnival (fasnacht) events cluster heavily by date+city with wildly varying titles, so title weight should be lower and geo weight higher. Political (versammlung) events have very consistent titles across sources, so title weight should be higher. Category-aware weights let the scoring pipeline adapt to these differences. Category-specific F1 reporting validates that the changes actually improve accuracy per category.

Output: CategoryWeightsConfig in config.py, resolve_weights in pipeline.py, category_weights in matching.yaml, evaluate_category_subset in harness.py, comprehensive tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07/07-RESEARCH.md

@src/event_dedup/matching/config.py
@src/event_dedup/matching/combiner.py
@src/event_dedup/matching/pipeline.py
@src/event_dedup/evaluation/harness.py
@src/event_dedup/evaluation/metrics.py
@config/matching.yaml
@tests/test_matching_config.py
@tests/test_combiner.py
@tests/test_pipeline.py
@tests/test_harness.py

<interfaces>
<!-- Key types and contracts the executor needs. -->

From src/event_dedup/matching/config.py:
```python
class ScoringWeights(BaseModel):
    date: float = 0.30
    geo: float = 0.25
    title: float = 0.30
    description: float = 0.15

class MatchingConfig(BaseModel):
    scoring: ScoringWeights = ScoringWeights()
    thresholds: ThresholdConfig = ThresholdConfig()
    geo: GeoConfig = GeoConfig()
    date: DateConfig = DateConfig()
    title: TitleConfig = TitleConfig()
    cluster: ClusterConfig = ClusterConfig()
    canonical: CanonicalConfig = CanonicalConfig()
    ai: AIMatchingConfig = AIMatchingConfig()

def load_matching_config(path: Path) -> MatchingConfig
```

From src/event_dedup/matching/combiner.py:
```python
@dataclass(frozen=True)
class SignalScores:
    date: float; geo: float; title: float; description: float

def combined_score(scores: SignalScores, weights: ScoringWeights | None = None) -> float
def decide(score: float, thresholds: ThresholdConfig | None = None) -> str
```

From src/event_dedup/matching/pipeline.py:
```python
def score_candidate_pairs(events: list[dict], config: MatchingConfig) -> MatchResult
# Currently: score = combined_score(signals, config.scoring)
# Change to: weights = resolve_weights(evt_a, evt_b, config); score = combined_score(signals, weights)
```

From src/event_dedup/evaluation/metrics.py:
```python
@dataclass
class MetricsResult:
    precision: float; recall: float; f1: float
    true_positives: int; false_positives: int; false_negatives: int; true_negatives: int
    total_ground_truth_same: int; total_ground_truth_different: int; total_predicted_same: int

def compute_metrics(predicted_same, ground_truth_same, ground_truth_different) -> MetricsResult
```

Event dict schema:
```python
{
    "id": str, "title": str, "title_normalized": str,
    "source_type": str, "source_code": str,
    "categories": list[str] | None,  # e.g. ["fasnacht", "kinder"]
    "blocking_keys": list[str], ...
}
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Category-aware weight config and pipeline resolution</name>
  <files>
    src/event_dedup/matching/config.py
    src/event_dedup/matching/pipeline.py
    config/matching.yaml
    tests/test_matching_config.py
    tests/test_pipeline.py
  </files>
  <action>
**1. Add category weight config to `src/event_dedup/matching/config.py`:**

Add a new model and fields to MatchingConfig:

```python
class CategoryWeightsConfig(BaseModel):
    """Category-specific scoring weight overrides with priority ordering."""
    priority: list[str] = []  # Ordered list: first matching shared category wins
    overrides: dict[str, ScoringWeights] = {}  # category_name -> ScoringWeights
```

Add to MatchingConfig:
```python
class MatchingConfig(BaseModel):
    scoring: ScoringWeights = ScoringWeights()
    thresholds: ThresholdConfig = ThresholdConfig()
    geo: GeoConfig = GeoConfig()
    date: DateConfig = DateConfig()
    title: TitleConfig = TitleConfig()
    cluster: ClusterConfig = ClusterConfig()
    canonical: CanonicalConfig = CanonicalConfig()
    ai: AIMatchingConfig = AIMatchingConfig()
    category_weights: CategoryWeightsConfig = CategoryWeightsConfig()
```

**2. Add `resolve_weights` function to `src/event_dedup/matching/pipeline.py`:**

Add BEFORE the `score_candidate_pairs` function:

```python
def resolve_weights(
    event_a: dict, event_b: dict, config: MatchingConfig
) -> ScoringWeights:
    """Select scoring weights based on shared event categories.

    Checks if both events share a category that has weight overrides.
    Uses the priority list to determine which override takes precedence
    when multiple categories overlap.

    Returns the default config.scoring if no category-specific override applies.
    """
    if not config.category_weights.priority:
        return config.scoring

    cats_a = set(event_a.get("categories") or [])
    cats_b = set(event_b.get("categories") or [])
    shared = cats_a & cats_b

    if not shared:
        return config.scoring

    for cat in config.category_weights.priority:
        if cat in shared and cat in config.category_weights.overrides:
            return config.category_weights.overrides[cat]

    return config.scoring
```

Import `ScoringWeights` from config at the top of pipeline.py:
```python
from event_dedup.matching.config import MatchingConfig, ScoringWeights
```
(Note: `MatchingConfig` is already imported. Just add `ScoringWeights` to the existing import if not already there.)

**3. Integrate `resolve_weights` into `score_candidate_pairs`:**

In the `for id_a, id_b in pairs:` loop, change:

```python
        score = combined_score(signals, config.scoring)
```

to:

```python
        weights = resolve_weights(evt_a, evt_b, config)
        score = combined_score(signals, weights)
```

This is the ONLY change to `score_candidate_pairs`. The combiner is NOT modified -- it still receives a `ScoringWeights` instance, just potentially a category-specific one.

**4. Add category_weights to `config/matching.yaml`:**

Add at the end of the file (after the canonical section):

```yaml
# --- Category-aware weight overrides ---
# When both events in a pair share a category listed here,
# use these weights instead of the default scoring weights.
# Priority determines which override applies when multiple categories match.
category_weights:
  priority:
    - fasnacht
    - versammlung
  overrides:
    fasnacht:
      date: 0.30
      geo: 0.30
      title: 0.25         # Lower: carnival titles vary wildly between sources
      description: 0.15
    versammlung:
      date: 0.25
      geo: 0.20
      title: 0.40         # Higher: political events have very consistent titles
      description: 0.15
```

Note: Conservative weight adjustments per research recommendations. fasnacht title weight lowered from 0.30 to 0.25 (not extreme), geo raised from 0.25 to 0.30. versammlung title raised from 0.30 to 0.40.

**5. Extend `tests/test_matching_config.py`:**

Add a new test class:

```python
class TestCategoryWeightsConfig:
    """Tests for category-aware weight configuration."""

    def test_default_empty(self) -> None:
        """Default category_weights has empty priority and overrides."""
        cfg = MatchingConfig()
        assert cfg.category_weights.priority == []
        assert cfg.category_weights.overrides == {}

    def test_load_from_yaml(self, tmp_path: Path) -> None:
        """Category weights load correctly from YAML."""
        config_path = tmp_path / "matching.yaml"
        config_path.write_text(yaml.dump({
            "category_weights": {
                "priority": ["fasnacht", "versammlung"],
                "overrides": {
                    "fasnacht": {
                        "date": 0.30, "geo": 0.30,
                        "title": 0.25, "description": 0.15,
                    },
                    "versammlung": {
                        "date": 0.25, "geo": 0.20,
                        "title": 0.40, "description": 0.15,
                    }
                }
            }
        }))
        cfg = load_matching_config(config_path)
        assert cfg.category_weights.priority == ["fasnacht", "versammlung"]
        assert cfg.category_weights.overrides["fasnacht"].title == 0.25
        assert cfg.category_weights.overrides["versammlung"].title == 0.40

    def test_load_real_config_category_weights(self) -> None:
        """The shipped config/matching.yaml includes category_weights."""
        cfg = load_matching_config(Path("config/matching.yaml"))
        assert "fasnacht" in cfg.category_weights.priority
        assert "fasnacht" in cfg.category_weights.overrides
        assert cfg.category_weights.overrides["fasnacht"].title == 0.25

    def test_partial_override_preserves_defaults(self, tmp_path: Path) -> None:
        """Category weights config doesn't affect other defaults."""
        config_path = tmp_path / "matching.yaml"
        config_path.write_text(yaml.dump({
            "category_weights": {
                "priority": ["fasnacht"],
                "overrides": {
                    "fasnacht": {"date": 0.35, "geo": 0.35, "title": 0.20, "description": 0.10}
                }
            }
        }))
        cfg = load_matching_config(config_path)
        # Default scoring unchanged
        assert cfg.scoring.title == 0.30
        assert cfg.scoring.date == 0.30
        # Category override applied
        assert cfg.category_weights.overrides["fasnacht"].title == 0.20
```

**6. Extend `tests/test_pipeline.py`:**

Add tests for resolve_weights and category-aware scoring. Import `resolve_weights`:

```python
from event_dedup.matching.pipeline import resolve_weights
```

Add new test class:

```python
class TestResolveWeights:
    """Tests for category-aware weight resolution."""

    def _config_with_categories(self) -> MatchingConfig:
        from event_dedup.matching.config import CategoryWeightsConfig
        return MatchingConfig(
            category_weights=CategoryWeightsConfig(
                priority=["fasnacht", "versammlung"],
                overrides={
                    "fasnacht": ScoringWeights(date=0.30, geo=0.30, title=0.25, description=0.15),
                    "versammlung": ScoringWeights(date=0.25, geo=0.20, title=0.40, description=0.15),
                }
            )
        )

    def test_shared_category_uses_override(self) -> None:
        """Events sharing a priority category get override weights."""
        config = self._config_with_categories()
        evt_a = {"categories": ["fasnacht", "kinder"]}
        evt_b = {"categories": ["fasnacht"]}
        weights = resolve_weights(evt_a, evt_b, config)
        assert weights.title == 0.25
        assert weights.geo == 0.30

    def test_no_shared_category_uses_default(self) -> None:
        """Events with no shared category get default weights."""
        config = self._config_with_categories()
        evt_a = {"categories": ["musik"]}
        evt_b = {"categories": ["sport"]}
        weights = resolve_weights(evt_a, evt_b, config)
        assert weights == config.scoring

    def test_no_categories_uses_default(self) -> None:
        """Events without categories field get default weights."""
        config = self._config_with_categories()
        evt_a = {}
        evt_b = {"categories": ["fasnacht"]}
        weights = resolve_weights(evt_a, evt_b, config)
        assert weights == config.scoring

    def test_none_categories_uses_default(self) -> None:
        """Events with None categories get default weights."""
        config = self._config_with_categories()
        evt_a = {"categories": None}
        evt_b = {"categories": ["fasnacht"]}
        weights = resolve_weights(evt_a, evt_b, config)
        assert weights == config.scoring

    def test_priority_order_respected(self) -> None:
        """First matching priority category wins."""
        config = self._config_with_categories()
        evt_a = {"categories": ["fasnacht", "versammlung"]}
        evt_b = {"categories": ["fasnacht", "versammlung"]}
        weights = resolve_weights(evt_a, evt_b, config)
        # fasnacht has higher priority (listed first)
        assert weights.title == 0.25  # fasnacht weights

    def test_empty_priority_uses_default(self) -> None:
        """Empty priority list means no overrides."""
        config = MatchingConfig()  # default has empty priority
        evt_a = {"categories": ["fasnacht"]}
        evt_b = {"categories": ["fasnacht"]}
        weights = resolve_weights(evt_a, evt_b, config)
        assert weights == config.scoring

    def test_shared_category_not_in_overrides_uses_default(self) -> None:
        """Shared category in priority but not in overrides uses default."""
        from event_dedup.matching.config import CategoryWeightsConfig
        config = MatchingConfig(
            category_weights=CategoryWeightsConfig(
                priority=["musik"],  # in priority but no override defined
                overrides={}
            )
        )
        evt_a = {"categories": ["musik"]}
        evt_b = {"categories": ["musik"]}
        weights = resolve_weights(evt_a, evt_b, config)
        assert weights == config.scoring
```

Add an integration test for category-aware scoring:

```python
    def test_category_aware_scoring_integration(self) -> None:
        """Full pipeline with category-aware weights produces different scores."""
        from event_dedup.matching.config import CategoryWeightsConfig

        events = [
            make_event(
                id="a1",
                title_normalized="fastnachtumzug waldkirch",
                source_code="src_a",
                blocking_keys=["2026-03-01:waldkirch"],
                dates=[{"date": "2026-03-01"}],
                geo_latitude=48.09,
                geo_longitude=7.96,
                geo_confidence=0.95,
            ),
            make_event(
                id="b1",
                title_normalized="grosser umzug waldkirch",
                source_code="src_b",
                blocking_keys=["2026-03-01:waldkirch"],
                dates=[{"date": "2026-03-01"}],
                geo_latitude=48.09,
                geo_longitude=7.96,
                geo_confidence=0.95,
            ),
        ]
        # Add categories to the events
        events[0]["categories"] = ["fasnacht"]
        events[1]["categories"] = ["fasnacht"]

        config_with_cats = MatchingConfig(
            category_weights=CategoryWeightsConfig(
                priority=["fasnacht"],
                overrides={
                    "fasnacht": ScoringWeights(date=0.30, geo=0.30, title=0.25, description=0.15),
                }
            )
        )
        config_without_cats = MatchingConfig()

        result_with = score_candidate_pairs(events, config_with_cats)
        result_without = score_candidate_pairs(events, config_without_cats)

        # Scores should differ because title weight changed
        assert len(result_with.decisions) == 1
        assert len(result_without.decisions) == 1
        # With lower title weight (0.25 vs 0.30) and higher geo weight (0.30 vs 0.25),
        # the combined score changes for pairs with high geo but lower title match
        assert result_with.decisions[0].combined_score_value != result_without.decisions[0].combined_score_value
```

Import `ScoringWeights` at the top of test_pipeline.py:
```python
from event_dedup.matching.config import MatchingConfig, ScoringWeights, ThresholdConfig
```

**7. No changes to `tests/test_combiner.py`:**

The combiner itself is unchanged. All existing combiner tests should pass without modification. This validates the design decision that weight resolution happens upstream in the pipeline, not inside the combiner.
  </action>
  <verify>
    .venv/bin/python -m pytest tests/test_matching_config.py tests/test_pipeline.py tests/test_combiner.py -x --tb=short -q
  </verify>
  <done>
    - CategoryWeightsConfig model exists with priority list and overrides dict
    - MatchingConfig has category_weights field (defaults to empty)
    - resolve_weights function selects weights based on shared categories
    - score_candidate_pairs uses resolve_weights before calling combined_score
    - config/matching.yaml has category_weights for fasnacht (title=0.25) and versammlung (title=0.40)
    - combiner.py is completely unchanged
    - All existing pipeline and combiner tests pass unchanged
    - New tests verify priority ordering, fallback to defaults, and integration
  </done>
</task>

<task type="auto">
  <name>Task 2: Category-specific F1 evaluation in harness</name>
  <files>
    src/event_dedup/evaluation/harness.py
    tests/test_harness.py
  </files>
  <action>
**1. Add `evaluate_category_subset` function to `src/event_dedup/evaluation/harness.py`:**

Add this as a new standalone function (not a method on a class):

```python
def evaluate_category_subset(
    ground_truth_same: set[tuple[str, str]],
    ground_truth_different: set[tuple[str, str]],
    predicted_same: set[tuple[str, str]],
    events_by_id: dict[str, dict],
    category: str,
) -> MetricsResult:
    """Compute evaluation metrics for a specific event category subset.

    Filters ground truth and predicted pairs to only include those where
    at least one event in the pair has the specified category. Then
    computes precision/recall/F1 on the filtered subset.

    Args:
        ground_truth_same: All ground truth "same" pairs.
        ground_truth_different: All ground truth "different" pairs.
        predicted_same: All predicted "same" pairs.
        events_by_id: Dict mapping event IDs to event dicts (must include "categories" field).
        category: Category to filter by.

    Returns:
        MetricsResult for the category subset.
    """
    def pair_has_category(pair: tuple[str, str], cat: str) -> bool:
        a_id, b_id = pair
        cats_a = set(events_by_id.get(a_id, {}).get("categories") or [])
        cats_b = set(events_by_id.get(b_id, {}).get("categories") or [])
        return cat in cats_a or cat in cats_b

    gt_same_cat = {p for p in ground_truth_same if pair_has_category(p, category)}
    gt_diff_cat = {p for p in ground_truth_different if pair_has_category(p, category)}
    pred_cat = {p for p in predicted_same if pair_has_category(p, category)}

    return compute_metrics(pred_cat, gt_same_cat, gt_diff_cat)
```

**2. Add `run_category_evaluation` async function to harness.py:**

This wraps the full multi-signal evaluation with per-category breakdown:

```python
async def run_category_evaluation(
    session: AsyncSession,
    config: MatchingConfig,
    categories: list[str] | None = None,
) -> dict[str, MetricsResult]:
    """Run multi-signal evaluation with per-category F1 breakdown.

    Runs the standard multi-signal evaluation, then computes metrics
    for each specified category (or discovers categories from events).

    Args:
        session: Async SQLAlchemy session.
        config: Full matching configuration.
        categories: Categories to evaluate. If None, uses categories
            from config.category_weights.priority (if any), otherwise
            discovers from event data.

    Returns:
        Dict mapping category name to MetricsResult. Includes "overall"
        key for the full dataset metrics.
    """
    gt_same, gt_diff = await load_ground_truth(session)

    # Load all source events
    result = await session.execute(
        select(SourceEvent).options(selectinload(SourceEvent.dates))
    )
    source_events = result.scalars().all()

    events = []
    for evt in source_events:
        events.append(
            {
                "id": evt.id,
                "title": evt.title,
                "title_normalized": evt.title_normalized,
                "short_description": evt.short_description,
                "short_description_normalized": evt.short_description_normalized,
                "description": evt.description,
                "highlights": evt.highlights,
                "location_name": evt.location_name,
                "location_city": evt.location_city,
                "location_district": evt.location_district,
                "location_street": evt.location_street,
                "location_zipcode": evt.location_zipcode,
                "geo_latitude": evt.geo_latitude,
                "geo_longitude": evt.geo_longitude,
                "geo_confidence": evt.geo_confidence,
                "source_code": evt.source_code,
                "source_type": evt.source_type,
                "blocking_keys": evt.blocking_keys,
                "categories": evt.categories,
                "is_family_event": evt.is_family_event,
                "is_child_focused": evt.is_child_focused,
                "admission_free": evt.admission_free,
                "dates": [
                    {
                        "date": str(d.date),
                        "start_time": str(d.start_time) if d.start_time else None,
                        "end_time": str(d.end_time) if d.end_time else None,
                        "end_date": str(d.end_date) if d.end_date else None,
                    }
                    for d in evt.dates
                ],
            }
        )

    events_by_id = {e["id"]: e for e in events}
    predicted = generate_predictions_multisignal(events, config)
    overall_metrics = compute_metrics(predicted, gt_same, gt_diff)

    # Determine categories to evaluate
    if categories is None:
        if config.category_weights.priority:
            categories = list(config.category_weights.priority)
        else:
            # Discover categories from events
            all_cats: set[str] = set()
            for evt in events:
                for cat in evt.get("categories") or []:
                    all_cats.add(cat)
            categories = sorted(all_cats)

    results: dict[str, MetricsResult] = {"overall": overall_metrics}
    for cat in categories:
        results[cat] = evaluate_category_subset(
            gt_same, gt_diff, predicted, events_by_id, cat
        )

    # Print category breakdown
    print("\n" + "=" * 90)
    print("  Category-Specific Evaluation Results")
    print("=" * 90)
    print(f"  {'Category':>15s}  {'Precision':>10s}  {'Recall':>8s}  {'F1':>8s}  {'TP':>5s}  {'FP':>5s}  {'FN':>5s}  {'GT Same':>8s}")
    print("-" * 90)
    for cat_name in ["overall"] + categories:
        m = results[cat_name]
        label = cat_name.upper() if cat_name == "overall" else cat_name
        print(
            f"  {label:>15s}  "
            f"{m.precision:>10.4f}  {m.recall:>8.4f}  {m.f1:>8.4f}  "
            f"{m.true_positives:>5d}  {m.false_positives:>5d}  {m.false_negatives:>5d}  "
            f"{m.total_ground_truth_same:>8d}"
        )
    print("=" * 90 + "\n")

    return results
```

**3. Extend `tests/test_harness.py`:**

Add a test class for `evaluate_category_subset` (pure function, no DB needed):

```python
from event_dedup.evaluation.harness import evaluate_category_subset

class TestEvaluateCategorySubset:
    """Tests for category-specific evaluation."""

    def _make_events_by_id(self) -> dict[str, dict]:
        return {
            "e1": {"id": "e1", "categories": ["fasnacht", "kinder"]},
            "e2": {"id": "e2", "categories": ["fasnacht"]},
            "e3": {"id": "e3", "categories": ["musik"]},
            "e4": {"id": "e4", "categories": ["musik"]},
            "e5": {"id": "e5", "categories": ["versammlung"]},
            "e6": {"id": "e6", "categories": ["versammlung"]},
        }

    def test_filters_to_category(self) -> None:
        """Only pairs involving the target category are evaluated."""
        events = self._make_events_by_id()
        gt_same = {("e1", "e2"), ("e3", "e4")}  # fasnacht pair + musik pair
        gt_diff = {("e5", "e6")}
        predicted = {("e1", "e2"), ("e3", "e4")}

        result = evaluate_category_subset(gt_same, gt_diff, predicted, events, "fasnacht")
        # Only e1-e2 pair involves fasnacht
        assert result.total_ground_truth_same == 1
        assert result.true_positives == 1

    def test_category_false_negative(self) -> None:
        """Missing a category-specific pair is a false negative."""
        events = self._make_events_by_id()
        gt_same = {("e1", "e2")}
        gt_diff: set[tuple[str, str]] = set()
        predicted: set[tuple[str, str]] = set()  # missed the pair

        result = evaluate_category_subset(gt_same, gt_diff, predicted, events, "fasnacht")
        assert result.false_negatives == 1
        assert result.recall == 0.0

    def test_category_false_positive(self) -> None:
        """Predicting a category pair that is labeled different is a false positive."""
        events = self._make_events_by_id()
        gt_same: set[tuple[str, str]] = set()
        gt_diff = {("e1", "e2")}
        predicted = {("e1", "e2")}

        result = evaluate_category_subset(gt_same, gt_diff, predicted, events, "fasnacht")
        assert result.false_positives == 1
        assert result.precision == 0.0

    def test_empty_category_returns_zeros(self) -> None:
        """Category with no matching pairs returns zero metrics."""
        events = self._make_events_by_id()
        gt_same = {("e1", "e2")}
        gt_diff: set[tuple[str, str]] = set()
        predicted = {("e1", "e2")}

        result = evaluate_category_subset(gt_same, gt_diff, predicted, events, "sport")
        assert result.total_ground_truth_same == 0
        assert result.total_predicted_same == 0

    def test_pair_included_if_either_event_has_category(self) -> None:
        """A pair is included if EITHER event has the target category."""
        events = {
            "e1": {"id": "e1", "categories": ["fasnacht"]},
            "e2": {"id": "e2", "categories": ["musik"]},  # no fasnacht
        }
        gt_same = {("e1", "e2")}
        gt_diff: set[tuple[str, str]] = set()
        predicted = {("e1", "e2")}

        result = evaluate_category_subset(gt_same, gt_diff, predicted, events, "fasnacht")
        # e1 has fasnacht, so this pair is included
        assert result.total_ground_truth_same == 1
        assert result.true_positives == 1

    def test_missing_categories_field_excluded(self) -> None:
        """Events without categories field are excluded from category subsets."""
        events = {
            "e1": {"id": "e1"},  # no categories
            "e2": {"id": "e2", "categories": ["fasnacht"]},
        }
        gt_same = {("e1", "e2")}
        gt_diff: set[tuple[str, str]] = set()
        predicted = {("e1", "e2")}

        result = evaluate_category_subset(gt_same, gt_diff, predicted, events, "fasnacht")
        # e2 has fasnacht, so pair is included (either event having it is enough)
        assert result.total_ground_truth_same == 1
```
  </action>
  <verify>
    .venv/bin/python -m pytest tests/test_harness.py tests/test_pipeline.py -x --tb=short -q
  </verify>
  <done>
    - evaluate_category_subset filters ground truth and predicted pairs by category then computes metrics
    - run_category_evaluation runs full multi-signal evaluation with per-category F1 breakdown
    - Category subset evaluation includes pairs where EITHER event has the target category
    - Tests cover filtering, false positives, false negatives, empty categories, and edge cases
    - All existing harness tests pass unchanged
  </done>
</task>

</tasks>

<verification>
Run the full test suite to ensure no regressions:

```bash
.venv/bin/python -m pytest tests/ -x --tb=short -q
```

All existing tests must pass. New tests in test_matching_config.py, test_pipeline.py, and test_harness.py must also pass.

Verify that the combiner tests are completely unaffected:
```bash
.venv/bin/python -m pytest tests/test_combiner.py -v
```
</verification>

<success_criteria>
1. CategoryWeightsConfig model with priority list and ScoringWeights overrides per category
2. resolve_weights function selects weights based on shared categories with priority ordering
3. score_candidate_pairs uses resolve_weights before calling combined_score
4. config/matching.yaml has category_weights for fasnacht (title=0.25, geo=0.30) and versammlung (title=0.40)
5. evaluate_category_subset computes F1 for category-specific ground truth subsets
6. run_category_evaluation provides per-category F1 breakdown with formatted output
7. Combiner is completely unchanged -- all combiner tests pass without modification
8. All 25+ existing test files pass without modification
</success_criteria>

<output>
After completion, create `.planning/phases/07/07-02-SUMMARY.md`
</output>
