---
phase: 08-dynamic-config
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/event_dedup/models/config_settings.py
  - src/event_dedup/models/__init__.py
  - src/event_dedup/config/encryption.py
  - src/event_dedup/config/settings.py
  - src/event_dedup/api/schemas.py
  - src/event_dedup/api/routes/config.py
  - src/event_dedup/api/app.py
  - src/event_dedup/matching/config.py
  - src/event_dedup/worker/orchestrator.py
  - src/event_dedup/worker/watcher.py
  - src/event_dedup/worker/__main__.py
  - config/alembic/versions/005_add_config_settings.py
  - tests/test_config_api.py
  - pyproject.toml
autonomous: true
requirements:
  - CFG-01
  - CFG-03
  - CFG-04
  - CFG-05

must_haves:
  truths:
    - "GET /api/config returns all matching parameters with current values (defaults if no DB config exists)"
    - "PATCH /api/config accepts partial updates and persists the full merged config to DB"
    - "Gemini API key is never returned in GET responses; has_api_key boolean indicates presence"
    - "PATCH with ai_api_key stores it encrypted; empty string clears it"
    - "Worker loads config from DB at each pipeline run, falls back to YAML defaults"
    - "AI enabled/disabled toggle is persisted and returned in config"
  artifacts:
    - path: "src/event_dedup/models/config_settings.py"
      provides: "SQLAlchemy model for config_settings table"
      contains: "class ConfigSettings"
    - path: "src/event_dedup/config/encryption.py"
      provides: "Fernet encrypt/decrypt utility for API key"
      exports: ["encrypt_value", "decrypt_value"]
    - path: "src/event_dedup/api/routes/config.py"
      provides: "GET and PATCH /api/config endpoints"
      exports: ["router"]
    - path: "config/alembic/versions/005_add_config_settings.py"
      provides: "Alembic migration for config_settings table"
      contains: "config_settings"
    - path: "tests/test_config_api.py"
      provides: "API tests for config endpoints"
      min_lines: 100
  key_links:
    - from: "src/event_dedup/api/routes/config.py"
      to: "src/event_dedup/models/config_settings.py"
      via: "SQLAlchemy ORM query"
      pattern: "ConfigSettings"
    - from: "src/event_dedup/api/routes/config.py"
      to: "src/event_dedup/matching/config.py"
      via: "Pydantic validation"
      pattern: "MatchingConfig"
    - from: "src/event_dedup/worker/orchestrator.py"
      to: "src/event_dedup/models/config_settings.py"
      via: "load_config_for_run function"
      pattern: "ConfigSettings"
    - from: "src/event_dedup/api/routes/config.py"
      to: "src/event_dedup/config/encryption.py"
      via: "encrypt API key on PATCH"
      pattern: "encrypt_value"
---

<objective>
Build the complete backend for the dynamic configuration system: database model, migration, encryption utility, REST API endpoints (GET/PATCH), API schemas, worker config loading from DB, and tests.

Purpose: Replace the current YAML-only config with a database-backed config that can be read and updated via API, with changes taking effect on the next pipeline run. The Gemini API key must be stored encrypted and never returned in API responses.

Output: Working GET/PATCH /api/config endpoints, config_settings DB table, worker loading config from DB per pipeline run, comprehensive tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08/08-RESEARCH.md

@src/event_dedup/matching/config.py
@src/event_dedup/models/base.py
@src/event_dedup/models/__init__.py
@src/event_dedup/config/settings.py
@src/event_dedup/api/app.py
@src/event_dedup/api/deps.py
@src/event_dedup/api/schemas.py
@src/event_dedup/worker/orchestrator.py
@src/event_dedup/worker/watcher.py
@src/event_dedup/worker/__main__.py
@tests/conftest.py

<interfaces>
<!-- Key types and contracts the executor needs -->

From src/event_dedup/matching/config.py:
```python
class ScoringWeights(BaseModel):
    date: float = 0.30; geo: float = 0.25; title: float = 0.30; description: float = 0.15

class ThresholdConfig(BaseModel):
    high: float = 0.75; low: float = 0.35

class GeoConfig(BaseModel):
    max_distance_km: float = 10.0; min_confidence: float = 0.85; neutral_score: float = 0.5

class DateConfig(BaseModel):
    time_tolerance_minutes: int = 30; time_close_minutes: int = 90
    close_factor: float = 0.7; far_factor: float = 0.3

class TitleConfig(BaseModel):
    primary_weight: float = 0.7; secondary_weight: float = 0.3
    blend_lower: float = 0.40; blend_upper: float = 0.80
    cross_source_type: TitleConfig | None = None

class ClusterConfig(BaseModel):
    max_cluster_size: int = 15; min_internal_similarity: float = 0.40

class FieldStrategies(BaseModel):
    title: str = "longest_non_generic"; short_description: str = "longest"; ...

class CanonicalConfig(BaseModel):
    field_strategies: FieldStrategies = FieldStrategies()

class AIMatchingConfig(BaseModel):
    enabled: bool = False; api_key: str = ""; model: str = "gemini-2.5-flash"
    temperature: float = 0.1; max_output_tokens: int = 2048
    max_concurrent_requests: int = 5; confidence_threshold: float = 0.6
    cache_enabled: bool = True
    cost_per_1m_input_tokens: float = 0.30; cost_per_1m_output_tokens: float = 2.50

class CategoryWeightsConfig(BaseModel):
    priority: list[str] = []; overrides: dict[str, ScoringWeights] = {}

class MatchingConfig(BaseModel):
    scoring: ScoringWeights; thresholds: ThresholdConfig; geo: GeoConfig
    date: DateConfig; title: TitleConfig; cluster: ClusterConfig
    canonical: CanonicalConfig; ai: AIMatchingConfig
    category_weights: CategoryWeightsConfig

def load_matching_config(path: Path) -> MatchingConfig:
```

From src/event_dedup/models/base.py:
```python
class Base(DeclarativeBase): ...
```

From src/event_dedup/api/deps.py:
```python
async def get_db() -> AsyncGenerator[AsyncSession, None]: ...
```

From src/event_dedup/config/settings.py:
```python
class Settings(BaseSettings):
    model_config = SettingsConfigDict(env_prefix="EVENT_DEDUP_")
    gemini_api_key: str = ""
    matching_config_path: Path = Path("config/matching.yaml")
    # ... other fields
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Database model, migration, encryption, and API schemas</name>
  <files>
    src/event_dedup/models/config_settings.py
    src/event_dedup/models/__init__.py
    src/event_dedup/config/encryption.py
    src/event_dedup/config/settings.py
    src/event_dedup/api/schemas.py
    config/alembic/versions/005_add_config_settings.py
    pyproject.toml
  </files>
  <action>
1. Add `cryptography` dependency: `uv add cryptography`

2. Create `src/event_dedup/config/encryption.py`:
   - `get_fernet() -> Fernet`: reads `EVENT_DEDUP_ENCRYPTION_KEY` env var, returns Fernet instance. If env var not set, return None (graceful fallback).
   - `encrypt_value(value: str) -> str`: encrypts with Fernet. If no encryption key configured, store the value as-is with a "plain:" prefix (development fallback, log a warning via structlog).
   - `decrypt_value(token: str) -> str`: decrypts with Fernet. If token starts with "plain:", return the rest as-is (backward compat with unencrypted values).
   - This graceful fallback avoids requiring an encryption key for development/testing while still supporting encryption in production.

3. Create `src/event_dedup/models/config_settings.py`:
   ```python
   class ConfigSettings(Base):
       __tablename__ = "config_settings"
       id: Mapped[int] = mapped_column(primary_key=True, default=1)
       config_json: Mapped[dict] = mapped_column(JSON, server_default="{}", default=dict)
       encrypted_api_key: Mapped[str | None] = mapped_column(sa.Text, nullable=True)
       updated_at: Mapped[datetime] = mapped_column(sa.DateTime, server_default=sa.text("CURRENT_TIMESTAMP"))
       updated_by: Mapped[str] = mapped_column(sa.String(100), server_default="system")
   ```
   Use `sqlalchemy.types.JSON` (not PostgreSQL-specific dialect) so SQLite tests work. Import `datetime` from `datetime` module.

4. Update `src/event_dedup/models/__init__.py`: Add `ConfigSettings` to imports and `__all__`.

5. Add `encryption_key: str = ""` to `Settings` in `src/event_dedup/config/settings.py` (env var: `EVENT_DEDUP_ENCRYPTION_KEY`).

6. Create Alembic migration `config/alembic/versions/005_add_config_settings.py`:
   - Verify the actual `down_revision` by checking the latest migration head (likely `004_add_audit_log`).
   - Create `config_settings` table with columns: `id` (Integer PK), `config_json` (JSON, server_default="{}"), `encrypted_api_key` (Text, nullable), `updated_at` (DateTime, server_default CURRENT_TIMESTAMP), `updated_by` (String(100), server_default "system").

7. Add Pydantic API schemas to `src/event_dedup/api/schemas.py`:
   - `AIConfigResponse(BaseModel)`: All AIMatchingConfig fields EXCEPT `api_key`. Include `enabled`, `model`, `temperature`, `max_output_tokens`, `max_concurrent_requests`, `confidence_threshold`, `cache_enabled`, `cost_per_1m_input_tokens`, `cost_per_1m_output_tokens`.
   - `ConfigResponse(BaseModel)`: `scoring: ScoringWeights`, `thresholds: ThresholdConfig`, `geo: GeoConfig`, `date: DateConfig`, `title: TitleConfig`, `cluster: ClusterConfig`, `canonical: CanonicalConfig`, `ai: AIConfigResponse`, `category_weights: CategoryWeightsConfig`, `has_api_key: bool`, `updated_at: str | None`.
   - `ConfigUpdateRequest(BaseModel)`: All section fields as Optional (None default). Plus `ai_api_key: str | None = None` as a top-level write-only field. All fields use `exclude_unset=True` pattern.

Helper function `config_to_response(config: MatchingConfig) -> dict` that converts a MatchingConfig to a dict suitable for ConfigResponse (replacing the ai section with AIConfigResponse by excluding api_key).
  </action>
  <verify>
    <automated>cd /Users/svenkarl/workspaces/event-deduplication && uv run python -c "
from event_dedup.models.config_settings import ConfigSettings
from event_dedup.config.encryption import encrypt_value, decrypt_value
from event_dedup.api.schemas import ConfigResponse, ConfigUpdateRequest, AIConfigResponse
from event_dedup.matching.config import MatchingConfig

# Test encryption round-trip (plaintext fallback)
enc = encrypt_value('test-key-123')
assert decrypt_value(enc) == 'test-key-123'

# Test ConfigResponse can be created from MatchingConfig
config = MatchingConfig()
ai_dict = config.ai.model_dump()
ai_dict.pop('api_key', None)
resp = ConfigResponse(
    scoring=config.scoring, thresholds=config.thresholds, geo=config.geo,
    date=config.date, title=config.title, cluster=config.cluster,
    canonical=config.canonical, ai=AIConfigResponse(**ai_dict),
    category_weights=config.category_weights, has_api_key=False, updated_at=None,
)
assert resp.has_api_key == False
assert not hasattr(resp.ai, 'api_key')

print('All checks passed')
"</automated>
  </verify>
  <done>ConfigSettings SQLAlchemy model exists, encryption utility works with graceful fallback, API schemas exclude API key from responses, migration file created, cryptography dependency added.</done>
</task>

<task type="auto">
  <name>Task 2: API endpoints, worker config loading, and tests</name>
  <files>
    src/event_dedup/api/routes/config.py
    src/event_dedup/api/app.py
    src/event_dedup/matching/config.py
    src/event_dedup/worker/orchestrator.py
    src/event_dedup/worker/watcher.py
    src/event_dedup/worker/__main__.py
    tests/test_config_api.py
  </files>
  <action>
1. Create `src/event_dedup/api/routes/config.py` with a FastAPI `APIRouter`:

   **GET /api/config** (response_model=ConfigResponse):
   - Query `ConfigSettings` row with id=1 from DB.
   - If no row exists, create a `MatchingConfig()` with all defaults and return it (with `has_api_key=False`, `updated_at=None`).
   - If row exists, construct `MatchingConfig(**row.config_json)` and return via `config_to_response()` with `has_api_key=(row.encrypted_api_key is not None)`.

   **PATCH /api/config** (response_model=ConfigResponse):
   - Accept `ConfigUpdateRequest` body.
   - Load current config: if DB row exists with config_json, use `MatchingConfig(**row.config_json)`. Otherwise load YAML defaults via `load_matching_config(get_settings().matching_config_path)`.
   - Deep merge: `request.model_dump(exclude_unset=True, exclude={"ai_api_key"})` into current config dict. Use a recursive `deep_merge(base: dict, updates: dict) -> dict` helper that only overwrites leaf values present in updates. Then validate with `MatchingConfig(**merged)`.
   - Handle API key: if `request.ai_api_key` is not None: empty string -> clear (set encrypted_api_key=None), non-empty -> `encrypt_value(request.ai_api_key)`.
   - Before storing config_json, remove `ai.api_key` from the dict (it must never be in the JSON column).
   - Upsert the row (create if id=1 doesn't exist, update if it does).
   - Commit and return the updated config.

2. Register the router in `src/event_dedup/api/app.py`:
   ```python
   from event_dedup.api.routes.config import router as config_router
   app.include_router(config_router)
   ```

3. Add `load_config_for_run()` function to `src/event_dedup/matching/config.py`:
   ```python
   async def load_config_for_run(session_factory) -> MatchingConfig:
   ```
   - Open a session, query `ConfigSettings` with id=1.
   - If row exists and has config_json: construct `MatchingConfig(**row.config_json)`. If `row.encrypted_api_key`, decrypt it and set `config.ai.api_key`.
   - If no row: fall back to `load_matching_config()` with settings path. Also check `settings.gemini_api_key` env var for backward compat.
   - Return the config.

4. Modify `src/event_dedup/worker/orchestrator.py`:
   - Import `load_config_for_run` from `event_dedup.matching.config`.
   - In `process_new_file()`: change signature to accept `matching_config: MatchingConfig | None = None`. At the top, if matching_config is None, call `matching_config = await load_config_for_run(session_factory)`. This allows the worker to load fresh config per run while still accepting a config for tests.
   - Apply the same pattern to `process_file_batch()`.
   - `process_existing_files()` also gets the same pattern.

5. Modify `src/event_dedup/worker/watcher.py`:
   - `watch_and_process()`: Remove `matching_config` parameter. The orchestrator functions now load config per-run from DB internally (or fall back to YAML). Pass `matching_config=None` to orchestrator calls.

6. Modify `src/event_dedup/worker/__main__.py`:
   - Remove the line `matching_config = load_matching_config(...)` and the env var override block.
   - Remove `matching_config` from calls to `process_existing_files` and `watch_and_process`.
   - The orchestrator now handles config loading per-run.

7. Create `tests/test_config_api.py` with pytest-asyncio tests using the existing `api_client` and `test_session_factory` fixtures:
   - `test_get_config_defaults`: GET /api/config returns 200 with all default values, `has_api_key=False`.
   - `test_patch_config_scoring`: PATCH with `{"scoring": {"date": 0.4}}` returns updated scoring.date=0.4, other scoring fields unchanged at defaults.
   - `test_patch_config_preserves_unset`: PATCH scoring, then PATCH thresholds -- scoring changes are preserved (not reset to defaults).
   - `test_patch_api_key_not_in_get`: PATCH with `{"ai_api_key": "test-key"}` returns `has_api_key=True`. GET /api/config still has `has_api_key=True` but no api_key field in the ai section.
   - `test_clear_api_key`: PATCH with `{"ai_api_key": ""}` clears the key, `has_api_key=False`.
   - `test_patch_ai_enabled_toggle`: PATCH with `{"ai": {"enabled": true}}` returns `ai.enabled=True`. PATCH with `{"ai": {"enabled": false}}` returns `ai.enabled=False`.
   - `test_deep_merge_nested`: PATCH with `{"title": {"primary_weight": 0.8}}` preserves other title fields.
   - `test_config_round_trip`: PATCH complex config with category_weights and canonical field_strategies, verify GET returns the same values.
   - `test_load_config_for_run`: Test the `load_config_for_run` function directly with a seeded ConfigSettings row.

   Use the existing fixture patterns from conftest.py (api_client for HTTP tests, test_session_factory for unit tests).
  </action>
  <verify>
    <automated>cd /Users/svenkarl/workspaces/event-deduplication && uv run pytest tests/test_config_api.py -x -v</automated>
  </verify>
  <done>GET /api/config returns defaults or DB config. PATCH /api/config accepts partial updates, stores encrypted API key, never leaks API key in responses. Worker loads config from DB per pipeline run with YAML fallback. All tests pass. Existing tests still pass (no regressions from worker signature changes).</done>
</task>

</tasks>

<verification>
1. `uv run pytest tests/test_config_api.py -x -v` -- all config API tests pass
2. `uv run pytest tests/ -x --timeout=60` -- no regressions in existing tests
3. `uv run python -c "from event_dedup.models import ConfigSettings; print('Model OK')"` -- model importable
4. GET /api/config returns 200 with complete config structure
5. PATCH /api/config with `{"scoring": {"date": 0.5}}` returns updated config
6. PATCH /api/config with `{"ai_api_key": "sk-test"}` sets key; GET shows `has_api_key: true` but no key value
</verification>

<success_criteria>
- Config API endpoints respond correctly with full MatchingConfig parameter set
- API key is stored encrypted, never returned in GET responses
- Partial updates merge correctly (don't reset unset fields)
- Worker loads config from DB per run, falls back to YAML
- All new and existing tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/08/08-01-SUMMARY.md`
</output>
