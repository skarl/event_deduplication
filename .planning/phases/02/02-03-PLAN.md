---
phase: 02-matching-pipeline
plan: 03
type: execute
wave: 3
depends_on: ["02-02"]
files_modified:
  - src/event_dedup/clustering/__init__.py
  - src/event_dedup/clustering/graph_cluster.py
  - src/event_dedup/clustering/coherence.py
  - tests/test_clustering.py
autonomous: true
requirements:
  - MTCH-10

must_haves:
  truths:
    - "Match pairs form a graph and connected components produce event clusters"
    - "Singleton events (no matches) become their own cluster of size 1"
    - "Over-large clusters (>max_cluster_size) are flagged for review, not silently accepted"
    - "Clusters with low average internal similarity are flagged for review"
    - "Flagged clusters are separated from valid clusters for downstream processing"
  artifacts:
    - path: "src/event_dedup/clustering/graph_cluster.py"
      provides: "cluster_matches() using networkx connected_components"
      exports: ["cluster_matches", "ClusterResult"]
    - path: "src/event_dedup/clustering/coherence.py"
      provides: "is_cluster_coherent() validation logic"
      exports: ["is_cluster_coherent"]
    - path: "tests/test_clustering.py"
      provides: "Unit tests for clustering and coherence"
      min_lines: 80
  key_links:
    - from: "src/event_dedup/clustering/graph_cluster.py"
      to: "src/event_dedup/matching/pipeline.py"
      via: "MatchDecisionRecord list from score_candidate_pairs"
      pattern: "MatchDecisionRecord|decision.*match"
    - from: "src/event_dedup/clustering/graph_cluster.py"
      to: "networkx"
      via: "nx.Graph + nx.connected_components"
      pattern: "nx\\.Graph|connected_components"
    - from: "src/event_dedup/clustering/coherence.py"
      to: "src/event_dedup/matching/config.py"
      via: "ClusterConfig (max_cluster_size, min_internal_similarity)"
      pattern: "ClusterConfig|max_cluster_size|min_internal_similarity"
---

<objective>
Build graph-based clustering using networkx connected_components on match pairs, with coherence validation to flag suspicious clusters (over-large, low internal similarity).

Purpose: Pairwise match decisions are insufficient -- event A matches B and B matches C means A, B, C are the same event even if A-C was never directly compared. Graph clustering captures this transitivity. Coherence validation catches "bridge" events that falsely connect separate real-world events.

Output: Clustering module with coherence checks, flagged cluster tracking, comprehensive tests.
</objective>

<execution_context>
@.planning/phases/02/02-RESEARCH.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/phases/02/02-CONTEXT.md
@.planning/phases/02/02-RESEARCH.md
@.planning/phases/02/02-01-SUMMARY.md
@.planning/phases/02/02-02-SUMMARY.md

<interfaces>
<!-- From Plan 02-01 -->

From src/event_dedup/matching/config.py:
```python
class ClusterConfig(BaseModel):
    max_cluster_size: int = 15
    min_internal_similarity: float = 0.40
```

<!-- From Plan 02-02 -->

From src/event_dedup/matching/pipeline.py:
```python
@dataclass
class MatchDecisionRecord:
    event_id_a: str
    event_id_b: str
    signals: SignalScores
    combined_score_value: float
    decision: str  # "match" | "ambiguous" | "no_match"
    tier: str = "deterministic"

@dataclass
class MatchResult:
    decisions: list[MatchDecisionRecord]
    pair_stats: CandidatePairStats
    match_count: int
    ambiguous_count: int
    no_match_count: int

def get_match_pairs(result: MatchResult) -> set[tuple[str, str]]: ...
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Graph Clustering with networkx Connected Components</name>
  <files>
    src/event_dedup/clustering/__init__.py
    src/event_dedup/clustering/graph_cluster.py
    src/event_dedup/clustering/coherence.py
    tests/test_clustering.py
  </files>
  <action>
1. **Create `src/event_dedup/clustering/__init__.py`**:
   - Re-export: `from .graph_cluster import cluster_matches, ClusterResult`

2. **Create `src/event_dedup/clustering/graph_cluster.py`**:
   - Import `networkx as nx`, `dataclass` from dataclasses
   - Import `MatchDecisionRecord` from `event_dedup.matching.pipeline`
   - Import `ClusterConfig` from `event_dedup.matching.config`
   - Import `is_cluster_coherent` from `.coherence`
   - `@dataclass` class `ClusterResult`:
     - `clusters: list[set[str]]` -- valid clusters (sets of event IDs)
     - `flagged_clusters: list[set[str]]` -- over-large or incoherent clusters (still included, but marked)
     - `singleton_count: int` -- how many single-event clusters (for stats)
     - `total_cluster_count: int` -- total clusters including singletons and flagged
   - Function `cluster_matches(decisions: list[MatchDecisionRecord], all_event_ids: list[str], config: ClusterConfig, events_by_id: dict[str, dict] | None = None) -> ClusterResult`:
     - Create `G = nx.Graph()`
     - For each decision where `decision.decision == "match"`:
       - `G.add_edge(decision.event_id_a, decision.event_id_b, weight=decision.combined_score_value)`
     - Add ALL event IDs as nodes (ensures singletons with no matches get their own cluster):
       - `for event_id in all_event_ids: G.add_node(event_id)`
     - Get connected components: `components = list(nx.connected_components(G))`
     - For each component:
       - If len == 1: add to `clusters`, increment `singleton_count`
       - If `is_cluster_coherent(component, G, config, events_by_id)`: add to `clusters`
       - Else: add to `flagged_clusters`
     - Return `ClusterResult(clusters=..., flagged_clusters=..., singleton_count=..., total_cluster_count=len(components))`

3. **Create `src/event_dedup/clustering/coherence.py`**:
   - Import `networkx as nx`
   - Import `ClusterConfig` from `event_dedup.matching.config`
   - Function `is_cluster_coherent(cluster: set[str], graph: nx.Graph, config: ClusterConfig, events_by_id: dict[str, dict] | None = None) -> bool`:
     - **Size check**: If `len(cluster) > config.max_cluster_size` (15): return False
     - **Internal similarity check**: Get subgraph, extract edge weights, compute average. If avg < `config.min_internal_similarity` (0.40): return False
     - **Date spread check** (only if events_by_id provided): For each event in cluster, collect all unique date strings from `events_by_id[eid].get("dates", [])`. If distinct date count > 3 (reasonable since events might span multi-day): return False. This catches clusters that span unrelated dates.
     - If all checks pass: return True

4. **Create `tests/test_clustering.py`** with comprehensive tests:
   - **Test: Two matched events form one cluster**
     - Create 2 MatchDecisionRecords with decision="match"
     - Verify 1 cluster with both event IDs
   - **Test: Transitive closure**
     - A-B match, B-C match, but A-C never compared
     - Verify single cluster {A, B, C}
   - **Test: Separate clusters**
     - A-B match, C-D match (no connection between groups)
     - Verify 2 clusters: {A,B} and {C,D}
   - **Test: Singleton events**
     - Events E and F have no matches
     - Verify they each get their own singleton cluster
     - Verify singleton_count reflects this
   - **Test: Mix of clusters and singletons**
     - A-B match, C standalone
     - Verify clusters = [{A,B}, {C}], singleton_count = 1
   - **Test: Over-large cluster flagged**
     - Create a chain of 20 events all connected (A-B, B-C, ..., S-T)
     - With max_cluster_size=15, the resulting cluster of 20 should be flagged
     - Verify it's in flagged_clusters, not clusters
   - **Test: Low-similarity cluster flagged**
     - Create 3-node cluster where edge weights are all 0.30 (below min_internal_similarity=0.40)
     - Verify flagged
   - **Test: Coherent cluster passes**
     - Create 3-node cluster with edge weights all 0.80 (above min_internal_similarity=0.40)
     - Verify in clusters, not flagged
   - **Test: No-match and ambiguous decisions ignored**
     - Create decisions with decision="no_match" and "ambiguous"
     - Verify no edges added to graph (events become singletons)
   - **Test: Date spread coherence**
     - Create cluster spanning 5 different dates -> flagged
     - Create cluster spanning 2 dates -> coherent
   - **Test: all_event_ids ensures completeness**
     - Pass all_event_ids with events not in any decision
     - Verify those events appear as singleton clusters
  </action>
  <verify>
    <automated>cd /Users/svenkarl/workspaces/event-deduplication && uv run pytest tests/test_clustering.py -x -v</automated>
  </verify>
  <done>
    - `cluster_matches` takes match decisions + all event IDs, returns ClusterResult with valid and flagged clusters
    - Connected components correctly group transitively linked events
    - Singletons (unmatched events) get their own cluster
    - Over-large clusters (>15) are flagged
    - Low-similarity clusters (avg weight < 0.40) are flagged
    - Date-spread clusters (>3 distinct dates) are flagged when events_by_id provided
    - Only "match" decisions create edges; "no_match" and "ambiguous" are ignored
    - All tests pass
  </done>
</task>

</tasks>

<verification>
```bash
# Clustering tests pass
cd /Users/svenkarl/workspaces/event-deduplication && uv run pytest tests/test_clustering.py -x -v

# Import works
cd /Users/svenkarl/workspaces/event-deduplication && uv run python -c "from event_dedup.clustering import cluster_matches, ClusterResult; print('Clustering OK')"

# networkx connected_components works
cd /Users/svenkarl/workspaces/event-deduplication && uv run python -c "import networkx as nx; G = nx.Graph(); G.add_edge('a','b'); G.add_edge('b','c'); print(list(nx.connected_components(G)))"

# All prior tests still pass
cd /Users/svenkarl/workspaces/event-deduplication && uv run pytest tests/ -x --timeout=60
```
</verification>

<success_criteria>
1. `cluster_matches` produces ClusterResult with valid clusters, flagged clusters, singleton count
2. Connected components correctly handle transitive matches (A-B + B-C = {A,B,C})
3. Singleton events (no matches) appear as size-1 clusters
4. Over-large clusters (>max_cluster_size) are flagged, not silently accepted
5. Low-similarity clusters (avg edge weight < min_internal_similarity) are flagged
6. Only "match" decisions create graph edges
7. All tests pass
8. All prior tests still pass
</success_criteria>

<output>
After completion, create `.planning/phases/02/02-03-SUMMARY.md`
</output>
